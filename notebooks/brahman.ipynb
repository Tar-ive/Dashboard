{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNtTFQ5Y0w/eodiySWEfmlD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tar-ive/Dashboard/blob/main/brahman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out the System Architecture docs here: https://www.overleaf.com/read/ffzgqryyrgzm#22fb04"
      ],
      "metadata": {
        "id": "cY1zflRdqDg0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8Ov4DHAi41i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Optional\n",
        "import json\n",
        "\n",
        "# Configuration\n",
        "TAHIR_EKIN_ID = \"A5088154684\"  # Tahir Ekin's researcher ID\n",
        "EMAIL = \"your_email@example.com\"  # Replace with your actual email\n",
        "MAX_RESEARCHERS = 50\n",
        "\n",
        "def call_openalex_api(endpoint, params=None):\n",
        "    \"\"\"Make API calls with rate limiting and error handling\"\"\"\n",
        "    base_url = f\"https://api.openalex.org/{endpoint}\"\n",
        "    headers = {'User-Agent': f'mailto:{EMAIL}'}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        time.sleep(0.2)  # Rate limiting\n",
        "        return response.json()\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling {endpoint} API: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def get_texas_state_id():\n",
        "    \"\"\"Get Texas State University's OpenAlex ID.\"\"\"\n",
        "    params = {\n",
        "        'filter': 'display_name.search:texas state university',\n",
        "        'per-page': 1\n",
        "    }\n",
        "    response = call_openalex_api('institutions', params)\n",
        "    if response and 'results' in response and response['results']:\n",
        "        return response['results'][0]['id']\n",
        "    return None\n",
        "\n",
        "def fetch_top_researchers(institution_id, max_researchers=50):\n",
        "    \"\"\"Fetch the top cited researchers affiliated with an institution.\"\"\"\n",
        "    all_researchers = []\n",
        "    cursor = '*'\n",
        "\n",
        "    while cursor and len(all_researchers) < max_researchers:\n",
        "        try:\n",
        "            params = {\n",
        "                'filter': f'last_known_institutions.id:{institution_id}',\n",
        "                'per-page': min(100, max_researchers - len(all_researchers)),\n",
        "                'sort': 'cited_by_count:desc',\n",
        "                'cursor': cursor\n",
        "            }\n",
        "\n",
        "            response = call_openalex_api('authors', params)\n",
        "\n",
        "            if not response or 'results' not in response:\n",
        "                break\n",
        "\n",
        "            researchers = response['results']\n",
        "            if not researchers:\n",
        "                break\n",
        "\n",
        "            all_researchers.extend(researchers)\n",
        "\n",
        "            if len(all_researchers) >= max_researchers:\n",
        "                all_researchers = all_researchers[:max_researchers]\n",
        "                break\n",
        "\n",
        "            cursor = response.get('meta', {}).get('next_cursor')\n",
        "\n",
        "            if not cursor:\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching researchers: {str(e)}\")\n",
        "            break\n",
        "\n",
        "    return all_researchers\n",
        "\n",
        "def get_researcher_by_id(researcher_id):\n",
        "    \"\"\"Get a specific researcher by ID\"\"\"\n",
        "    try:\n",
        "        clean_id = researcher_id.split('/')[-1] if '/' in researcher_id else researcher_id\n",
        "        response = call_openalex_api(f'authors/{clean_id}')\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching researcher {researcher_id}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def reconstruct_abstract(inverted_index: Dict) -> str:\n",
        "    \"\"\"Reconstruct abstract text from OpenAlex inverted index format.\"\"\"\n",
        "    if not inverted_index:\n",
        "        return \"\"\n",
        "\n",
        "    word_positions = []\n",
        "    for word, positions in inverted_index.items():\n",
        "        for pos in positions:\n",
        "            word_positions.append((pos, word))\n",
        "\n",
        "    word_positions.sort(key=lambda x: x[0])\n",
        "    words = [word for _, word in word_positions]\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "def get_researcher_works(researcher_id):\n",
        "    \"\"\"Get all works for a researcher using cursor pagination\"\"\"\n",
        "    clean_id = researcher_id.split('/')[-1] if '/' in researcher_id else researcher_id\n",
        "\n",
        "    base_params = {\n",
        "        'filter': f'author.id:{clean_id}',\n",
        "        'per-page': 200,\n",
        "        'sort': 'cited_by_count:desc'\n",
        "    }\n",
        "\n",
        "    all_works = []\n",
        "    cursor = '*'\n",
        "\n",
        "    while cursor:\n",
        "        try:\n",
        "            params = base_params.copy()\n",
        "            params['cursor'] = cursor\n",
        "\n",
        "            response = call_openalex_api('works', params)\n",
        "\n",
        "            if not response or 'results' not in response:\n",
        "                break\n",
        "\n",
        "            works = response['results']\n",
        "            if not works:\n",
        "                break\n",
        "\n",
        "            all_works.extend(works)\n",
        "\n",
        "            cursor = response.get('meta', {}).get('next_cursor')\n",
        "\n",
        "            if not cursor:\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching works for researcher {clean_id}: {str(e)}\")\n",
        "            break\n",
        "\n",
        "    return all_works\n",
        "\n",
        "def extract_work_data(works: List[Dict], researcher_id: str, researcher_name: str) -> List[Dict]:\n",
        "    \"\"\"Extract work data including abstracts, topics, titles, and publication years.\"\"\"\n",
        "    extracted_data = []\n",
        "\n",
        "    for work in works:\n",
        "        # Extract basic work information\n",
        "        work_id = work.get('id', '')\n",
        "        title = work.get('display_name', '')\n",
        "        publication_year = work.get('publication_year', None)\n",
        "        doi = work.get('doi', '')\n",
        "        citations = work.get('cited_by_count', 0) or 0\n",
        "\n",
        "        # Extract and reconstruct abstract\n",
        "        abstract_inverted = work.get('abstract_inverted_index', {})\n",
        "        abstract = reconstruct_abstract(abstract_inverted)\n",
        "\n",
        "        # Extract topics\n",
        "        topics = work.get('topics', [])\n",
        "        topic_names = []\n",
        "        topic_scores = []\n",
        "\n",
        "        if topics and isinstance(topics, list):\n",
        "            for topic in topics[:5]:  # Limit to top 5 topics\n",
        "                if topic and isinstance(topic, dict):\n",
        "                    topic_names.append(topic.get('display_name', ''))\n",
        "                    topic_scores.append(topic.get('score', 0))\n",
        "\n",
        "        # Join topics with semicolon separator\n",
        "        topics_str = '; '.join(topic_names) if topic_names else ''\n",
        "        topic_scores_str = '; '.join([str(score) for score in topic_scores]) if topic_scores else ''\n",
        "\n",
        "        # Extract source information\n",
        "        primary_location = work.get('primary_location')\n",
        "        source_name = ''\n",
        "        if primary_location and isinstance(primary_location, dict):\n",
        "            source = primary_location.get('source')\n",
        "            if source and isinstance(source, dict):\n",
        "                source_name = source.get('display_name', '')\n",
        "\n",
        "        # Extract open access information\n",
        "        oa_info = work.get('open_access', {})\n",
        "        is_oa = False\n",
        "        oa_status = ''\n",
        "        if oa_info and isinstance(oa_info, dict):\n",
        "            is_oa = oa_info.get('is_oa', False)\n",
        "            oa_status = oa_info.get('oa_status', '')\n",
        "\n",
        "        # Extract work type\n",
        "        work_type = work.get('type', '')\n",
        "\n",
        "        # Extract concepts (different from topics)\n",
        "        concepts = work.get('concepts', [])\n",
        "        concept_names = []\n",
        "        if concepts and isinstance(concepts, list):\n",
        "            for concept in concepts[:5]:  # Limit to top 5 concepts\n",
        "                if concept and isinstance(concept, dict):\n",
        "                    concept_names.append(concept.get('display_name', ''))\n",
        "\n",
        "        concepts_str = '; '.join(concept_names) if concept_names else ''\n",
        "\n",
        "        extracted_data.append({\n",
        "            'researcher_id': researcher_id,\n",
        "            'researcher_name': researcher_name,\n",
        "            'work_id': work_id,\n",
        "            'title': title,\n",
        "            'abstract': abstract,\n",
        "            'topics': topics_str,\n",
        "            'topic_scores': topic_scores_str,\n",
        "            'concepts': concepts_str,\n",
        "            'publication_year': publication_year,\n",
        "            'work_type': work_type,\n",
        "            'doi': doi,\n",
        "            'citations': citations,\n",
        "            'source_name': source_name,\n",
        "            'is_open_access': is_oa,\n",
        "            'oa_status': oa_status,\n",
        "            'has_abstract': bool(abstract),\n",
        "            'num_topics': len(topic_names)\n",
        "        })\n",
        "\n",
        "    return extracted_data\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to extract works data for top Texas State University researchers\"\"\"\n",
        "\n",
        "    print(\"IMPORTANT: Please update the EMAIL variable with your actual email address!\")\n",
        "    print(f\"Current email: {EMAIL}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Step 1: Get Texas State University ID\n",
        "    print(\"Getting Texas State University ID...\")\n",
        "    texas_state_id = get_texas_state_id()\n",
        "    if not texas_state_id:\n",
        "        print(\"Could not find Texas State University ID\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found Texas State University ID: {texas_state_id}\")\n",
        "\n",
        "    # Step 2: Fetch top researchers\n",
        "    print(f\"\\nFetching top {MAX_RESEARCHERS} cited researchers from Texas State University...\")\n",
        "    researchers = fetch_top_researchers(texas_state_id, MAX_RESEARCHERS)\n",
        "\n",
        "    if not researchers:\n",
        "        print(\"Failed to fetch researchers\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(researchers)} researchers\")\n",
        "\n",
        "    # Step 3: Check if Tahir Ekin is in the list, if not add him\n",
        "    researcher_ids = [r['id'] for r in researchers]\n",
        "    tahir_ekin_included = any(TAHIR_EKIN_ID in rid for rid in researcher_ids)\n",
        "\n",
        "    if not tahir_ekin_included:\n",
        "        print(f\"\\nTahir Ekin (ID: {TAHIR_EKIN_ID}) not in top {MAX_RESEARCHERS}, adding him...\")\n",
        "        tahir_ekin_data = get_researcher_by_id(TAHIR_EKIN_ID)\n",
        "        if tahir_ekin_data:\n",
        "            researchers.append(tahir_ekin_data)\n",
        "            print(\"Tahir Ekin added successfully\")\n",
        "        else:\n",
        "            print(\"Failed to fetch Tahir Ekin's data\")\n",
        "    else:\n",
        "        print(f\"Tahir Ekin is already in the top {MAX_RESEARCHERS} researchers\")\n",
        "\n",
        "    # Step 4: Process each researcher and get their works\n",
        "    all_works_data = []\n",
        "\n",
        "    print(f\"\\nProcessing {len(researchers)} researchers and their works...\")\n",
        "\n",
        "    for i, researcher in enumerate(tqdm(researchers, desc=\"Processing researchers\")):\n",
        "        try:\n",
        "            researcher_id = researcher['id']\n",
        "            researcher_name = researcher['display_name']\n",
        "\n",
        "            print(f\"\\nProcessing: {researcher_name} ({researcher_id})\")\n",
        "\n",
        "            # Get all works for this researcher\n",
        "            works = get_researcher_works(researcher_id)\n",
        "\n",
        "            if works:\n",
        "                print(f\"Found {len(works)} works for {researcher_name}\")\n",
        "\n",
        "                # Extract work data\n",
        "                work_data = extract_work_data(works, researcher_id, researcher_name)\n",
        "                all_works_data.extend(work_data)\n",
        "\n",
        "                print(f\"Extracted data for {len(work_data)} works\")\n",
        "            else:\n",
        "                print(f\"No works found for {researcher_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing researcher {researcher.get('display_name', 'Unknown')}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Step 5: Create DataFrame and save to CSV\n",
        "    if all_works_data:\n",
        "        print(f\"\\nCreating DataFrame with {len(all_works_data)} total works...\")\n",
        "        df = pd.DataFrame(all_works_data)\n",
        "\n",
        "        # Save to CSV\n",
        "        filename = f\"texas_state_top_{MAX_RESEARCHERS}_researchers_works.csv\"\n",
        "        df.to_csv(filename, index=False)\n",
        "\n",
        "        print(f\"\\nData saved to: {filename}\")\n",
        "\n",
        "        # Display summary statistics\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"SUMMARY STATISTICS\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        print(f\"Total researchers processed: {df['researcher_id'].nunique()}\")\n",
        "        print(f\"Total works: {len(df)}\")\n",
        "        print(f\"Works with abstracts: {df['has_abstract'].sum()}\")\n",
        "        print(f\"Works without abstracts: {(~df['has_abstract']).sum()}\")\n",
        "        print(f\"Total citations: {df['citations'].sum():,}\")\n",
        "        print(f\"Average citations per work: {df['citations'].mean():.1f}\")\n",
        "        print(f\"Open access works: {df['is_open_access'].sum()}\")\n",
        "\n",
        "        # Year distribution\n",
        "        valid_years = df[df['publication_year'].notna() & (df['publication_year'] > 0)]\n",
        "        if not valid_years.empty:\n",
        "            print(f\"Publication year range: {valid_years['publication_year'].min():.0f} - {valid_years['publication_year'].max():.0f}\")\n",
        "\n",
        "        # Top researchers by total works\n",
        "        print(f\"\\nTop 10 researchers by number of works:\")\n",
        "        researcher_counts = df['researcher_name'].value_counts().head(10)\n",
        "        for name, count in researcher_counts.items():\n",
        "            print(f\"  {name}: {count} works\")\n",
        "\n",
        "        # Check if Tahir Ekin is included\n",
        "        tahir_works = df[df['researcher_name'].str.contains('Tahir', case=False, na=False)]\n",
        "        if not tahir_works.empty:\n",
        "            print(f\"\\nTahir Ekin's works: {len(tahir_works)}\")\n",
        "\n",
        "        print(f\"\\nDataFrame shape: {df.shape}\")\n",
        "        print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    else:\n",
        "        print(\"No works data extracted\")\n",
        "        return None\n",
        "\n",
        "# Run the extraction\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Texas State University Researchers Works Extractor\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"This script will:\")\n",
        "    print(f\"1. Get top {MAX_RESEARCHERS} cited researchers from Texas State University\")\n",
        "    print(\"2. Include Tahir Ekin even if not in top 50\")\n",
        "    print(\"3. Extract all works data for each researcher\")\n",
        "    print(\"4. Save combined data to CSV file\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    df = main()\n",
        "\n",
        "    if df is not None:\n",
        "        print(f\"\\n✅ Success! Data extracted and saved.\")\n",
        "        print(f\"📊 {len(df)} total works from {df['researcher_id'].nunique()} researchers\")\n",
        "    else:\n",
        "        print(\"\\n❌ Failed to extract data\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ufwmnxTAj_V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This CSV file contains comprehensive data about every published work (research papers, articles, etc.) from the top 50 most-cited researchers at Texas State University, plus Tahir Ekin's works. Each row represents a single publication with details including the work's title, reconstructed abstract, research topics with scores, publication year, citation count, source journal/venue, and open access status, along with the researcher's name and ID who authored it.\n",
        "\n",
        "(9086, 17)-> Shape\n",
        "\n",
        "Index(['researcher_id', 'researcher_name', 'work_id', 'title', 'abstract',\n",
        "       'topics', 'topic_scores', 'concepts', 'publication_year', 'work_type',\n",
        "       'doi', 'citations', 'source_name', 'is_open_access', 'oa_status',\n",
        "       'has_abstract', 'num_topics'],\n",
        "      dtype='object') -> columns"
      ],
      "metadata": {
        "id": "Yd0V5lkfkDsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import joblib\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class ResearcherProfileDatastore:\n",
        "    \"\"\"\n",
        "    A class to create and manage researcher profile embeddings and metadata.\n",
        "\n",
        "    Storage Structure:\n",
        "    ├── researcher_profiles_metadata.parquet     # Main metadata with recency weights\n",
        "    ├── researcher_embeddings.npy               # All embeddings as numpy array (N x 384)\n",
        "    ├── embedding_index.json                    # Maps work_id -> array position\n",
        "    ├── researcher_index.json                   # Maps researcher_id -> list of work_ids\n",
        "    └── datastore_info.json                     # Metadata about the datastore\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, drive_path=\"/content/drive/My Drive/datastore\"):\n",
        "        self.drive_path = drive_path\n",
        "        self.model = None\n",
        "        self.current_year = datetime.now().year\n",
        "\n",
        "    def load_model(self, model_name='all-MiniLM-L6-v2'):\n",
        "        \"\"\"\n",
        "        Load the sentence transformer model.\n",
        "        Using 'all-MiniLM-L6-v2': 384 dimensions, good balance of speed and quality.\n",
        "        \"\"\"\n",
        "        print(f\"Loading sentence transformer model: {model_name}\")\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        print(f\"Model loaded. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
        "        return self.model\n",
        "\n",
        "    def calculate_recency_weight(self, publication_year):\n",
        "        \"\"\"\n",
        "        Calculate recency weight: Wt = max(0, 1 - (CurrentYear - PublicationYear) / 10)\n",
        "\n",
        "        Args:\n",
        "            publication_year (int): Year of publication\n",
        "\n",
        "        Returns:\n",
        "            float: Recency weight between 0 and 1\n",
        "        \"\"\"\n",
        "        if pd.isna(publication_year) or publication_year == 0:\n",
        "            return 0.0\n",
        "\n",
        "        weight = max(0, 1 - (self.current_year - publication_year) / 10)\n",
        "        return round(weight, 4)\n",
        "\n",
        "    def create_text_for_embedding(self, title, abstract):\n",
        "        \"\"\"\n",
        "        Combine title and abstract for embedding.\n",
        "\n",
        "        Args:\n",
        "            title (str): Paper title\n",
        "            abstract (str): Paper abstract\n",
        "\n",
        "        Returns:\n",
        "            str: Combined text for embedding\n",
        "        \"\"\"\n",
        "        title = str(title) if pd.notna(title) else \"\"\n",
        "        abstract = str(abstract) if pd.notna(abstract) else \"\"\n",
        "\n",
        "        # Combine title and abstract with separator\n",
        "        if abstract:\n",
        "            return f\"{title}. {abstract}\"\n",
        "        else:\n",
        "            return title\n",
        "\n",
        "    def process_papers(self, csv_file_path):\n",
        "        \"\"\"\n",
        "        Process all papers from CSV file to create embeddings and metadata.\n",
        "\n",
        "        Args:\n",
        "            csv_file_path (str): Path to the CSV file with researcher works\n",
        "\n",
        "        Returns:\n",
        "            tuple: (metadata_df, embeddings_array, embedding_index, researcher_index)\n",
        "        \"\"\"\n",
        "        print(\"Loading data from CSV...\")\n",
        "        df = pd.read_csv(csv_file_path)\n",
        "        print(f\"Loaded {len(df)} papers from {df['researcher_id'].nunique()} researchers\")\n",
        "\n",
        "        # Calculate recency weights\n",
        "        print(\"Calculating recency weights...\")\n",
        "        df['recency_weight'] = df['publication_year'].apply(self.calculate_recency_weight)\n",
        "\n",
        "        # Prepare text for embeddings\n",
        "        print(\"Preparing text for embeddings...\")\n",
        "        df['embedding_text'] = df.apply(\n",
        "            lambda row: self.create_text_for_embedding(row['title'], row['abstract']),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        # Filter out papers with no text\n",
        "        valid_papers = df[df['embedding_text'].str.len() > 0].copy()\n",
        "        print(f\"Processing {len(valid_papers)} papers with valid text\")\n",
        "\n",
        "        if len(valid_papers) == 0:\n",
        "            raise ValueError(\"No papers with valid text found!\")\n",
        "\n",
        "        # Load model if not already loaded\n",
        "        if self.model is None:\n",
        "            self.load_model()\n",
        "\n",
        "        # Generate embeddings\n",
        "        print(\"Generating embeddings...\")\n",
        "        texts = valid_papers['embedding_text'].tolist()\n",
        "\n",
        "        # Process in batches to avoid memory issues\n",
        "        batch_size = 100\n",
        "        all_embeddings = []\n",
        "\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Creating embeddings\"):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "            batch_embeddings = self.model.encode(batch_texts, show_progress_bar=False)\n",
        "            all_embeddings.append(batch_embeddings)\n",
        "\n",
        "        # Combine all embeddings\n",
        "        embeddings_array = np.vstack(all_embeddings)\n",
        "        print(f\"Generated embeddings shape: {embeddings_array.shape}\")\n",
        "\n",
        "        # Create embedding index (work_id -> array position)\n",
        "        embedding_index = {}\n",
        "        researcher_index = {}\n",
        "\n",
        "        for idx, (_, row) in enumerate(valid_papers.iterrows()):\n",
        "            work_id = row['work_id']\n",
        "            researcher_id = row['researcher_id']\n",
        "\n",
        "            # Map work_id to embedding position\n",
        "            embedding_index[work_id] = idx\n",
        "\n",
        "            # Group by researcher_id\n",
        "            if researcher_id not in researcher_index:\n",
        "                researcher_index[researcher_id] = []\n",
        "            researcher_index[researcher_id].append(work_id)\n",
        "\n",
        "        print(f\"Created embedding index for {len(embedding_index)} papers\")\n",
        "        print(f\"Created researcher index for {len(researcher_index)} researchers\")\n",
        "\n",
        "        return valid_papers, embeddings_array, embedding_index, researcher_index\n",
        "\n",
        "    def save_datastore(self, metadata_df, embeddings_array, embedding_index, researcher_index):\n",
        "        \"\"\"\n",
        "        Save all components of the researcher profile datastore.\n",
        "\n",
        "        Args:\n",
        "            metadata_df (pd.DataFrame): Paper metadata with recency weights\n",
        "            embeddings_array (np.ndarray): All embeddings\n",
        "            embedding_index (dict): work_id -> array position mapping\n",
        "            researcher_index (dict): researcher_id -> list of work_ids mapping\n",
        "        \"\"\"\n",
        "        print(\"Saving researcher profile datastore...\")\n",
        "\n",
        "        # Ensure the datastore directory exists\n",
        "        os.makedirs(self.drive_path, exist_ok=True)\n",
        "\n",
        "        # Save metadata as Parquet (much faster than CSV)\n",
        "        metadata_path = os.path.join(self.drive_path, \"researcher_profiles_metadata.parquet\")\n",
        "        metadata_df.to_parquet(metadata_path, index=False)\n",
        "        print(f\"✅ Saved metadata: {metadata_path}\")\n",
        "\n",
        "        # Save embeddings as numpy array\n",
        "        embeddings_path = os.path.join(self.drive_path, \"researcher_embeddings.npy\")\n",
        "        np.save(embeddings_path, embeddings_array)\n",
        "        print(f\"✅ Saved embeddings: {embeddings_path}\")\n",
        "\n",
        "        # Save embedding index\n",
        "        embedding_index_path = os.path.join(self.drive_path, \"embedding_index.json\")\n",
        "        with open(embedding_index_path, 'w') as f:\n",
        "            json.dump(embedding_index, f, indent=2)\n",
        "        print(f\"✅ Saved embedding index: {embedding_index_path}\")\n",
        "\n",
        "        # Save researcher index\n",
        "        researcher_index_path = os.path.join(self.drive_path, \"researcher_index.json\")\n",
        "        with open(researcher_index_path, 'w') as f:\n",
        "            json.dump(researcher_index, f, indent=2)\n",
        "        print(f\"✅ Saved researcher index: {researcher_index_path}\")\n",
        "\n",
        "        # Save datastore info\n",
        "        datastore_info = {\n",
        "            \"created_at\": datetime.now().isoformat(),\n",
        "            \"total_papers\": len(metadata_df),\n",
        "            \"total_researchers\": metadata_df['researcher_id'].nunique(),\n",
        "            \"embedding_dimensions\": embeddings_array.shape[1],\n",
        "            \"model_used\": \"all-MiniLM-L6-v2\",\n",
        "            \"current_year_for_recency\": self.current_year,\n",
        "            \"files\": {\n",
        "                \"metadata\": \"researcher_profiles_metadata.parquet\",\n",
        "                \"embeddings\": \"researcher_embeddings.npy\",\n",
        "                \"embedding_index\": \"embedding_index.json\",\n",
        "                \"researcher_index\": \"researcher_index.json\"\n",
        "            },\n",
        "            \"usage_instructions\": {\n",
        "                \"load_metadata\": f\"pd.read_parquet('{self.drive_path}/researcher_profiles_metadata.parquet')\",\n",
        "                \"load_embeddings\": f\"np.load('{self.drive_path}/researcher_embeddings.npy')\",\n",
        "                \"load_indices\": f\"json.load(open('{self.drive_path}/embedding_index.json'))\",\n",
        "                \"get_embedding_by_work_id\": \"embeddings[embedding_index[work_id]]\",\n",
        "                \"get_researcher_papers\": \"researcher_index[researcher_id]\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        info_path = os.path.join(self.drive_path, \"datastore_info.json\")\n",
        "        with open(info_path, 'w') as f:\n",
        "            json.dump(datastore_info, f, indent=2)\n",
        "        print(f\"✅ Saved datastore info: {info_path}\")\n",
        "\n",
        "        return datastore_info\n",
        "\n",
        "    def load_datastore(self):\n",
        "        \"\"\"\n",
        "        Load the complete datastore for future use.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (metadata_df, embeddings_array, embedding_index, researcher_index, datastore_info)\n",
        "        \"\"\"\n",
        "        print(\"Loading researcher profile datastore...\")\n",
        "\n",
        "        # Load metadata\n",
        "        metadata_path = os.path.join(self.drive_path, \"researcher_profiles_metadata.parquet\")\n",
        "        metadata_df = pd.read_parquet(metadata_path)\n",
        "\n",
        "        # Load embeddings\n",
        "        embeddings_path = os.path.join(self.drive_path, \"researcher_embeddings.npy\")\n",
        "        embeddings_array = np.load(embeddings_path)\n",
        "\n",
        "        # Load indices\n",
        "        embedding_index_path = os.path.join(self.drive_path, \"embedding_index.json\")\n",
        "        with open(embedding_index_path, 'r') as f:\n",
        "            embedding_index = json.load(f)\n",
        "\n",
        "        researcher_index_path = os.path.join(self.drive_path, \"researcher_index.json\")\n",
        "        with open(researcher_index_path, 'r') as f:\n",
        "            researcher_index = json.load(f)\n",
        "\n",
        "        # Load info\n",
        "        info_path = os.path.join(self.drive_path, \"datastore_info.json\")\n",
        "        with open(info_path, 'r') as f:\n",
        "            datastore_info = json.load(f)\n",
        "\n",
        "        print(f\"✅ Loaded datastore with {len(metadata_df)} papers and {embeddings_array.shape} embeddings\")\n",
        "\n",
        "        return metadata_df, embeddings_array, embedding_index, researcher_index, datastore_info\n",
        "\n",
        "    def get_researcher_embeddings(self, researcher_id, embedding_index, researcher_index, embeddings_array):\n",
        "        \"\"\"\n",
        "        Get all embeddings for a specific researcher.\n",
        "\n",
        "        Args:\n",
        "            researcher_id (str): The researcher ID\n",
        "            embedding_index (dict): work_id -> position mapping\n",
        "            researcher_index (dict): researcher_id -> work_ids mapping\n",
        "            embeddings_array (np.ndarray): All embeddings\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Embeddings for the researcher's papers\n",
        "        \"\"\"\n",
        "        if researcher_id not in researcher_index:\n",
        "            return np.array([])\n",
        "\n",
        "        work_ids = researcher_index[researcher_id]\n",
        "        positions = [embedding_index[work_id] for work_id in work_ids if work_id in embedding_index]\n",
        "\n",
        "        return embeddings_array[positions]\n",
        "\n",
        "    def display_summary(self, metadata_df, datastore_info):\n",
        "        \"\"\"Display summary statistics of the created datastore.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"RESEARCHER PROFILE DATASTORE SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(f\"📊 Total papers: {len(metadata_df):,}\")\n",
        "        print(f\"👥 Total researchers: {metadata_df['researcher_id'].nunique()}\")\n",
        "        print(f\"🧠 Embedding dimensions: {datastore_info['embedding_dimensions']}\")\n",
        "        print(f\"📅 Current year (for recency): {datastore_info['current_year_for_recency']}\")\n",
        "\n",
        "        print(f\"\\n📝 Papers with abstracts: {metadata_df['has_abstract'].sum():,}\")\n",
        "        print(f\"📄 Papers without abstracts: {(~metadata_df['has_abstract']).sum():,}\")\n",
        "\n",
        "        print(f\"\\n⚡ Avg recency weight: {metadata_df['recency_weight'].mean():.3f}\")\n",
        "        print(f\"📊 Recency weight distribution:\")\n",
        "        print(f\"   High (>0.8): {(metadata_df['recency_weight'] > 0.8).sum():,} papers\")\n",
        "        print(f\"   Medium (0.4-0.8): {((metadata_df['recency_weight'] > 0.4) & (metadata_df['recency_weight'] <= 0.8)).sum():,} papers\")\n",
        "        print(f\"   Low (0-0.4): {(metadata_df['recency_weight'] <= 0.4).sum():,} papers\")\n",
        "\n",
        "        # Top researchers by number of papers\n",
        "        top_researchers = metadata_df['researcher_name'].value_counts().head(5)\n",
        "        print(f\"\\n🔬 Top 5 researchers by paper count:\")\n",
        "        for name, count in top_researchers.items():\n",
        "            print(f\"   {name}: {count} papers\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to create the researcher profile datastore.\"\"\"\n",
        "\n",
        "    # Initialize the datastore\n",
        "    datastore = ResearcherProfileDatastore()\n",
        "\n",
        "    # Specify your CSV file path (update this!)\n",
        "    csv_file_path = \"/content/texas_state_top_50_researchers_works.csv\"\n",
        "\n",
        "    print(\"🚀 Creating Researcher Profile Datastore\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    try:\n",
        "        # Process papers and create embeddings\n",
        "        metadata_df, embeddings_array, embedding_index, researcher_index = datastore.process_papers(csv_file_path)\n",
        "\n",
        "        # Save everything\n",
        "        datastore_info = datastore.save_datastore(metadata_df, embeddings_array, embedding_index, researcher_index)\n",
        "\n",
        "        # Display summary\n",
        "        datastore.display_summary(metadata_df, datastore_info)\n",
        "\n",
        "        print(f\"\\n✅ SUCCESS! Researcher Profile Datastore created.\")\n",
        "        print(f\"📁 Files saved to: {datastore.drive_path}\")\n",
        "\n",
        "        return datastore_info\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ ERROR: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Example usage functions\n",
        "def example_usage():\n",
        "    \"\"\"Show how to use the datastore after it's created.\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EXAMPLE: HOW TO USE THE DATASTORE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    code_examples = \"\"\"\n",
        "# 1. Load the complete datastore\n",
        "datastore = ResearcherProfileDatastore()\n",
        "metadata_df, embeddings, embedding_index, researcher_index, info = datastore.load_datastore()\n",
        "\n",
        "# 2. Get embedding for a specific paper\n",
        "work_id = \"https://openalex.org/W1234567890\"\n",
        "if work_id in embedding_index:\n",
        "    paper_embedding = embeddings[embedding_index[work_id]]\n",
        "    print(f\"Embedding shape: {paper_embedding.shape}\")\n",
        "\n",
        "# 3. Get all papers for a researcher\n",
        "researcher_id = \"https://openalex.org/A5088154684\"  # Tahir Ekin\n",
        "if researcher_id in researcher_index:\n",
        "    work_ids = researcher_index[researcher_id]\n",
        "    researcher_papers = metadata_df[metadata_df['work_id'].isin(work_ids)]\n",
        "    print(f\"Researcher has {len(researcher_papers)} papers\")\n",
        "\n",
        "# 4. Get embeddings for a researcher's papers\n",
        "researcher_embeddings = datastore.get_researcher_embeddings(\n",
        "    researcher_id, embedding_index, researcher_index, embeddings\n",
        ")\n",
        "print(f\"Researcher embeddings shape: {researcher_embeddings.shape}\")\n",
        "\n",
        "# 5. Find papers with high recency weights\n",
        "recent_papers = metadata_df[metadata_df['recency_weight'] > 0.8]\n",
        "print(f\"Found {len(recent_papers)} recent papers\")\n",
        "\n",
        "# 6. Calculate weighted average embedding for a researcher\n",
        "if len(researcher_embeddings) > 0:\n",
        "    weights = researcher_papers['recency_weight'].values\n",
        "    weighted_avg = np.average(researcher_embeddings, axis=0, weights=weights)\n",
        "    print(f\"Weighted average embedding shape: {weighted_avg.shape}\")\n",
        "\"\"\"\n",
        "\n",
        "    print(code_examples)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create the datastore\n",
        "    result = main()\n",
        "\n",
        "    if result:\n",
        "        # Show usage examples\n",
        "        example_usage()"
      ],
      "metadata": {
        "id": "fwAYFsa8kDAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation Summary:\n",
        "Why: We chose a file-based Google Drive approach for zero setup complexity, allowing immediate MVP development without cloud infrastructure, billing, or authentication overhead.\n",
        "\n",
        "How: Stores paper metadata in Parquet format, 384-dimensional embeddings as NumPy arrays, and creates JSON indices mapping work_id→array_position and researcher_id→work_ids for fast lookups.\n",
        "\n",
        "Cons: Hits memory/performance walls around 10k-50k papers due to loading entire embedding arrays into RAM, lacks similarity search optimization, and has no concurrent access or query filtering capabilities.\n",
        "\n",
        "Other Issues: Google Drive has 15GB storage limits and slow transfer speeds, JSON parsing becomes expensive with large indices, no automatic backup/versioning, and the monolithic file structure makes partial updates impossible.\n",
        "\n",
        "Migration Path: Will need to move to proper vector database (Pinecone/Weaviate) or PostgreSQL with pgvector extension when scaling beyond prototype phase."
      ],
      "metadata": {
        "id": "yZ0ePCNQnN3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a new folder in drive called datastrore and store all these files inside there and print new paths.\n",
        "# ✅ Saved metadata: /content/drive/My Drive/researcher_profiles_metadata.parquet\n",
        "# ✅ Saved embeddings: /content/drive/My Drive/researcher_embeddings.npy\n",
        "# ✅ Saved embedding index: /content/drive/My Drive/embedding_index.json\n",
        "# ✅ Saved researcher index: /content/drive/My Drive/researcher_index.json\n",
        "# ✅ Saved datastore info: /content/drive/My Drive/datastore_info.json\n",
        "\n",
        "# Create the new folder if it doesn't exist\n",
        "import os\n",
        "new_folder_path = \"/content/drive/My Drive/datastore\"\n",
        "if not os.path.exists(new_folder_path):\n",
        "    os.makedirs(new_folder_path)\n",
        "    print(f\"Created new folder: {new_folder_path}\")\n",
        "\n",
        "# Define the old and new paths\n",
        "old_paths = [\n",
        "    \"/content/drive/My Drive/researcher_profiles_metadata.parquet\",\n",
        "    \"/content/drive/My Drive/researcher_embeddings.npy\",\n",
        "    \"/content/drive/My Drive/embedding_index.json\",\n",
        "    \"/content/drive/My Drive/researcher_index.json\",\n",
        "    \"/content/drive/My Drive/datastore_info.json\"\n",
        "]\n",
        "\n",
        "new_paths = []\n",
        "\n",
        "# Move each file and store the new path\n",
        "for old_path in old_paths:\n",
        "    filename = os.path.basename(old_path)\n",
        "    new_path = os.path.join(new_folder_path, filename)\n",
        "\n",
        "    # Check if the file exists before attempting to move\n",
        "    if os.path.exists(old_path):\n",
        "        os.rename(old_path, new_path)\n",
        "        print(f\"Moved '{old_path}' to '{new_path}'\")\n",
        "        new_paths.append(new_path)\n",
        "    else:\n",
        "        print(f\"File not found, cannot move: {old_path}\")\n",
        "        # Append the intended new path even if the file wasn't moved,\n",
        "        # so the list of new paths is complete based on the source list.\n",
        "        new_paths.append(new_path)\n",
        "\n",
        "\n",
        "# Print the new paths\n",
        "print(\"\\nNew paths of the moved files:\")\n",
        "for path in new_paths:\n",
        "  print (path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RkzNdgj1pwuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fitz"
      ],
      "metadata": {
        "id": "gtTJtcUzqsyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "892859ef"
      },
      "source": [
        "# Uninstall fitz to ensure a clean install of PyMuPDF\n",
        "# !pip uninstall -y fitz\n",
        "\n",
        "# Install PyMuPDF, which is the recommended package\n",
        "!pip install PyMuPDF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic"
      ],
      "metadata": {
        "id": "9UyKZaBOrKMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V1"
      ],
      "metadata": {
        "id": "GbFbofign5Pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. IMPORT LIBRARIES AND DEFINE DATA STRUCTURE\n",
        "# ==============================================================================\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from google.colab import drive, userdata\n",
        "from transformers import pipeline\n",
        "import anthropic\n",
        "from dataclasses import dataclass, asdict\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "@dataclass\n",
        "class StructuredSolicitationObject:\n",
        "    \"\"\"\n",
        "    Structured object containing solicitation metadata and required skills.\n",
        "    \"\"\"\n",
        "    # Metadata\n",
        "    solicitation_id: str\n",
        "    title: str\n",
        "    abstract: str\n",
        "    processed_at: str\n",
        "    pdf_filename: str\n",
        "\n",
        "    # Skills from both paths\n",
        "    narrative_skills: List[str]  # From Claude API (Path A)\n",
        "    formal_topics: List[Dict]    # From OpenAlex classifier (Path B)\n",
        "\n",
        "    # Final combined checklist\n",
        "    required_skills_checklist: List[str]\n",
        "\n",
        "    # Processing details\n",
        "    text_length: int\n",
        "    processing_method: str = \"hybrid_deconstruction\"\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n",
        "        return asdict(self)\n",
        "\n",
        "    def to_json(self, filepath: str):\n",
        "        \"\"\"Save to JSON file.\"\"\"\n",
        "        with open(filepath, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.to_dict(), f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. PDF SOLICITATION PROCESSOR CLASS\n",
        "# ==============================================================================\n",
        "class PDFSolicitationProcessor:\n",
        "    \"\"\"\n",
        "    Processes PDF solicitations from a file path to extract required skills.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.claude_client = None\n",
        "        self.topic_classifier = None\n",
        "        self.setup_models()\n",
        "\n",
        "    def setup_models(self):\n",
        "        \"\"\"Initialize Claude API client and OpenAlex topic classifier.\"\"\"\n",
        "        print(\"Setting up models...\")\n",
        "        try:\n",
        "            api_key = userdata.get('ANTHROPIC_API_KEY')\n",
        "            self.claude_client = anthropic.Anthropic(api_key=api_key)\n",
        "            print(\"✅ Claude API client initialized\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Claude API setup failed: {e}\")\n",
        "\n",
        "        try:\n",
        "            print(\"Loading OpenAlex topic classifier...\")\n",
        "            self.topic_classifier = pipeline(\n",
        "                \"text-classification\",\n",
        "                model=\"OpenAlex/bert-base-multilingual-cased-finetuned-openalex-topic-classification-title-abstract\"\n",
        "            )\n",
        "            print(\"✅ OpenAlex topic classifier loaded\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Topic classifier setup failed: {e}\")\n",
        "\n",
        "    def _extract_text_from_pdf(self, filepath: str) -> Tuple[str, str, str]:\n",
        "        \"\"\"Extracts text content from a PDF given a file path.\"\"\"\n",
        "        if not os.path.exists(filepath):\n",
        "            raise FileNotFoundError(f\"The file was not found at: {filepath}\")\n",
        "\n",
        "        filename = os.path.basename(filepath)\n",
        "        print(f\"📄 Processing: {filename}\")\n",
        "\n",
        "        try:\n",
        "            doc = fitz.open(filepath)\n",
        "            full_text = \"\".join([page.get_text() for page in doc])\n",
        "            doc.close()\n",
        "\n",
        "            if not full_text.strip():\n",
        "                 raise ValueError(\"Extracted text is empty. The PDF might be an image.\")\n",
        "\n",
        "            title, abstract = self._extract_title_and_abstract(full_text, filename)\n",
        "            print(f\"✅ Extracted {len(full_text)} characters from PDF.\")\n",
        "            return filename, title, abstract\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error extracting text from PDF '{filename}': {e}\")\n",
        "            raise\n",
        "\n",
        "    def _extract_title_and_abstract(self, full_text: str, filename: str) -> Tuple[str, str]:\n",
        "        \"\"\"Extract title and abstract from full text using heuristics.\"\"\"\n",
        "        lines = [line.strip() for line in full_text.split('\\n') if line.strip()]\n",
        "        title = filename.replace('.pdf', '').replace('_', ' ').replace('-', ' ')\n",
        "        for line in lines[:15]: # Check more lines for title\n",
        "            if 20 < len(line) < 250 and not line.isupper(): # Avoid all-caps headers\n",
        "                title = line\n",
        "                break\n",
        "\n",
        "        abstract = \"\"\n",
        "        abstract_started = False\n",
        "        for line in lines:\n",
        "            line_lower = line.lower()\n",
        "            if not abstract_started and any(marker in line_lower for marker in ['abstract', 'summary', 'overview']):\n",
        "                abstract_started = True\n",
        "                if len(line) > len('abstract') + 10: abstract += line.split(maxsplit=1)[1]\n",
        "                continue\n",
        "            if abstract_started:\n",
        "                abstract += \" \" + line\n",
        "                if len(abstract) > 1500 or any(marker in line_lower for marker in ['introduction', 'background']):\n",
        "                    break\n",
        "        if not abstract: abstract = ' '.join(lines[:10]) # Fallback\n",
        "        return title.strip(), abstract.strip()[:2000] # Increased limit\n",
        "\n",
        "    def extract_narrative_skills_claude(self, text: str) -> List[str]:\n",
        "        \"\"\"Path A: Extract narrative skills using Claude API.\"\"\"\n",
        "        if not self.claude_client:\n",
        "            print(\"⚠️ Claude API not available, skipping narrative skills.\")\n",
        "            return []\n",
        "\n",
        "        prompt = f\"\"\"As an expert research program analyst, identify the 5-7 most critical and distinct areas of expertise required by this research solicitation. Focus on specific technical skills, domain knowledge, and methodological expertise.\n",
        "\n",
        "Solicitation text:\n",
        "---\n",
        "{text}\n",
        "---\n",
        "\n",
        "Provide your response as a numbered list of distinct expertise areas. Each item should be a concise phrase.\n",
        "\"\"\"\n",
        "        try:\n",
        "            print(\"🤖 Calling Claude API for narrative skills...\")\n",
        "            response = self.claude_client.messages.create(\n",
        "                model=\"claude-3-sonnet-20240229\",\n",
        "                max_tokens=1000,\n",
        "                temperature=0.2,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "            )\n",
        "            skills = self._parse_claude_response(response.content[0].text)\n",
        "            print(f\"✅ Extracted {len(skills)} narrative skills from Claude.\")\n",
        "            return skills\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Claude API call failed: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _parse_claude_response(self, response_text: str) -> List[str]:\n",
        "        \"\"\"Parse Claude's response to extract a list of skills.\"\"\"\n",
        "        skills = []\n",
        "        for line in response_text.split('\\n'):\n",
        "            line = line.strip()\n",
        "            if re.match(r'^\\d+\\.\\s*', line):\n",
        "                skill = re.sub(r'^\\d+\\.\\s*', '', line)\n",
        "                skills.append(skill.strip())\n",
        "        return skills[:7]\n",
        "\n",
        "    def extract_formal_topics_openalex(self, title: str, abstract: str) -> List[Dict]:\n",
        "      \"\"\"\n",
        "      Path B: Extract formal topics using OpenAlex classifier with corrected data structure handling.\n",
        "      \"\"\"\n",
        "      if not self.topic_classifier:\n",
        "          print(\"⚠️ Topic classifier not available, skipping formal topics.\")\n",
        "          return []\n",
        "\n",
        "      formatted_text = f\"<TITLE> {title}\\n<ABSTRACT> {abstract}\"\n",
        "      print(\"🔬 Running OpenAlex topic classification...\")\n",
        "\n",
        "      try:\n",
        "          # Get predictions from the model. The output is a simple list of dicts.\n",
        "          predictions = self.topic_classifier(formatted_text, top_k=10, truncation=True)\n",
        "          # print(f\"   [DEBUG] Raw output from OpenAlex model: {predictions}\") # You can remove this now\n",
        "\n",
        "          if not predictions:\n",
        "              print(\"   OpenAlex model returned no valid predictions.\")\n",
        "              return []\n",
        "\n",
        "          # --- CORRECTED LOOP ---\n",
        "          # We iterate directly over 'predictions', which is the list of dictionaries.\n",
        "          formal_topics = []\n",
        "          for topic in predictions:\n",
        "              # Check if the item is a dictionary with the keys we need\n",
        "              if isinstance(topic, dict) and 'label' in topic and 'score' in topic:\n",
        "                  # We can now lower the threshold since we see the scores are generally low\n",
        "                  if topic['score'] > 0.01: # Lowered threshold to include the results\n",
        "                      formal_topics.append({\n",
        "                          'topic': topic['label'],\n",
        "                          'score': round(topic['score'], 4)\n",
        "                      })\n",
        "              else:\n",
        "                  print(f\"   ⚠️ Skipping unexpected item in model predictions: {topic}\")\n",
        "\n",
        "          print(f\"✅ Extracted {len(formal_topics)} formal topics from OpenAlex.\")\n",
        "          return formal_topics\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"⚠️ An exception occurred during topic classification: {e}\")\n",
        "          return []\n",
        "\n",
        "    def fusion_logic(self, narrative_skills: List[str], formal_topics: List[Dict]) -> List[str]:\n",
        "        \"\"\"Combine narrative skills and formal topics, removing duplicates.\"\"\"\n",
        "        print(\"🔄 Applying fusion logic...\")\n",
        "        combined_skills = list(narrative_skills)\n",
        "        narrative_lower = ' '.join(narrative_skills).lower()\n",
        "\n",
        "        for topic in formal_topics:\n",
        "            topic_name = topic['topic'].split(': ', 1)[-1] # Remove ID like \"123: \"\n",
        "            is_duplicate = topic_name.lower() in narrative_lower\n",
        "            if not is_duplicate:\n",
        "                combined_skills.append(f\"Expertise in {topic_name}\")\n",
        "\n",
        "        print(f\"✅ Created final checklist with {len(combined_skills)} skills.\")\n",
        "        return combined_skills\n",
        "\n",
        "    def process_solicitation(self, pdf_filepath: str) -> Optional[StructuredSolicitationObject]:\n",
        "        \"\"\"Main processing pipeline for a PDF solicitation from a given path.\"\"\"\n",
        "        print(\"🚀 Starting PDF Solicitation Processing Pipeline\")\n",
        "        print(\"=\" * 60)\n",
        "        try:\n",
        "            filename, title, abstract = self._extract_text_from_pdf(pdf_filepath)\n",
        "\n",
        "            # Input for Claude can be a simple combination\n",
        "            claude_input_text = f\"Title: {title}. Abstract: {abstract}\"\n",
        "            print(f\"\\n📊 Text stats for analysis: {len(claude_input_text)} characters.\")\n",
        "\n",
        "            # Path A: Claude\n",
        "            narrative_skills = self.extract_narrative_skills_claude(claude_input_text)\n",
        "\n",
        "            # Path B: OpenAlex (uses corrected function call)\n",
        "            formal_topics = self.extract_formal_topics_openalex(title, abstract)\n",
        "\n",
        "            # Path C: Fusion\n",
        "            required_skills_checklist = self.fusion_logic(narrative_skills, formal_topics)\n",
        "\n",
        "            solicitation_obj = StructuredSolicitationObject(\n",
        "                solicitation_id=f\"SOL_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
        "                title=title, abstract=abstract,\n",
        "                processed_at=datetime.now().isoformat(),\n",
        "                pdf_filename=filename,\n",
        "                narrative_skills=narrative_skills,\n",
        "                formal_topics=formal_topics,\n",
        "                required_skills_checklist=required_skills_checklist,\n",
        "                text_length=len(claude_input_text))\n",
        "\n",
        "            output_filename = f\"{filename.replace('.pdf', '')}_analysis.json\"\n",
        "            solicitation_obj.to_json(output_filename)\n",
        "            print(f\"\\n✅ Processing complete! Saved to: {output_filename}\")\n",
        "            return solicitation_obj\n",
        "        except Exception as e:\n",
        "            print(f\"❌ A fatal error occurred during processing: {e}\")\n",
        "            return None\n",
        "\n",
        "    def display_results(self, solicitation_obj: Optional[StructuredSolicitationObject]):\n",
        "        \"\"\"Display processing results in a readable format.\"\"\"\n",
        "        if not solicitation_obj:\n",
        "            print(\"\\nNo results to display due to a processing error.\")\n",
        "            return\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"📋 SOLICITATION PROCESSING RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"🆔 ID: {solicitation_obj.solicitation_id}\")\n",
        "        print(f\"📄 File: {solicitation_obj.pdf_filename}\")\n",
        "        print(f\"📝 Title: {solicitation_obj.title}\")\n",
        "        print(f\"\\n🤖 Path A - Narrative Skills (Claude):\")\n",
        "        for i, skill in enumerate(solicitation_obj.narrative_skills, 1): print(f\"   {i}. {skill}\")\n",
        "        print(f\"\\n🔬 Path B - Formal Topics (OpenAlex):\")\n",
        "        for i, topic in enumerate(solicitation_obj.formal_topics, 1): print(f\"   {i}. {topic['topic']} (Score: {topic['score']:.3f})\")\n",
        "        print(f\"\\n✅ Final Hybrid Skills Checklist:\")\n",
        "        for i, skill in enumerate(solicitation_obj.required_skills_checklist, 1): print(f\"   {i}. {skill}\")\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. MAIN EXECUTION\n",
        "# ==============================================================================\n",
        "def main():\n",
        "    \"\"\"Main function to run the solicitation processing pipeline.\"\"\"\n",
        "    print(\"📄 PDF Solicitation Processor - Hybrid Deconstruction Engine\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # --- ⚠️ IMPORTANT ⚠️ ---\n",
        "    # UPDATE THIS PATH to the location of your PDF file in Google Drive.\n",
        "    # PDF_FILE_PATH = \"/content/drive/My Drive/datastore/NSF 24-569_ Mathematical Foundations of Artificial Intelligence (MFAI) _ NSF - National Science Foundation.pdf\"\n",
        "    PDF_FILE_PATH = \"/content/drive/MyDrive/datastore/NSF 25-530: Collaborations in Artificial Intelligence and Geosciences (CAIG) | NSF - National Science Foundation.pdf\"\n",
        "\n",
        "    # ---\n",
        "\n",
        "    try:\n",
        "        processor = PDFSolicitationProcessor()\n",
        "        result_obj = processor.process_solicitation(PDF_FILE_PATH)\n",
        "        processor.display_results(result_obj)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ An error occurred in the main function: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        print(\"Mounting Google Drive...\")\n",
        "        drive.mount('/content/drive', force_remount=False) # Force remount to ensure it's fresh\n",
        "        print(\"✅ Google Drive mounted successfully.\")\n",
        "        main()\n",
        "    except Exception as e:\n",
        "        print(f\"A critical error occurred: {e}\")"
      ],
      "metadata": {
        "id": "l3sdCJkhqvHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF_FILE_PATH = \"/content/drive/My Drive/datastore/NSF 24-569_ Mathematical Foundations of Artificial Intelligence (MFAI) _ NSF - National Science Foundation.pdf\"\n",
        "PDF_FILE_PATH = \"/content/drive/MyDrive/datastore/NSF 25-530: Collaborations in Artificial Intelligence and Geosciences (CAIG) | NSF - National Science Foundation.pdf\"\n",
        "processor = PDFSolicitationProcessor()\n",
        "result_obj = processor.process_solicitation(PDF_FILE_PATH)\n",
        "processor.display_results(result_obj)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "# Convert the result_obj to a dictionary\n",
        "result_dict = result_obj.to_dict()\n",
        "\n",
        "# Create a DataFrame from the dictionary\n",
        "# Since result_obj has nested lists/dicts, pandas might struggle to flatten it directly.\n",
        "# We can create a DataFrame with one row, where each column is the value of the corresponding key.\n",
        "# For list/dict values, they will be stored as objects in the cell.\n",
        "df_result = pd.DataFrame([result_dict])\n",
        "\n",
        "# Alternatively, if you want to normalize or flatten specific nested structures\n",
        "# you would need to process the dictionary before creating the DataFrame.\n",
        "# For example, to flatten formal_topics into separate columns:\n",
        "# df_formal_topics = pd.DataFrame(result_obj.formal_topics)\n",
        "# Then merge or combine this with the main DataFrame if needed.\n",
        "# For this task, a single-row DataFrame storing complex objects is sufficient.\n",
        "\n",
        "print(\"\\nDataFrame created from result_obj:\")\n",
        "print(df_result.head())\n",
        "print(f\"\\nDataFrame shape: {df_result.shape}\")\n",
        "print(f\"DataFrame columns: {list(df_result.columns)}\")\n"
      ],
      "metadata": {
        "id": "Y5waonpvwQPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result"
      ],
      "metadata": {
        "id": "RBw0TNWuxTq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skills"
      ],
      "metadata": {
        "id": "M-PLw621WS4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Ensure the previous cell ran successfully and result_obj exists\n",
        "if 'result_obj' in locals() and result_obj is not None:\n",
        "    # Convert the result_obj to a dictionary\n",
        "    result_dict = result_obj.to_dict()\n",
        "\n",
        "    # Create a DataFrame from the dictionary for inspection\n",
        "    df_result = pd.DataFrame([result_dict])\n",
        "\n",
        "    print(\"\\nDataFrame created from result_obj:\")\n",
        "    print(df_result.head())\n",
        "    print(f\"\\nDataFrame shape: {df_result.shape}\")\n",
        "    print(f\"DataFrame columns: {list(df_result.columns)}\")\n",
        "\n",
        "    # --- CRITICAL STEP ---\n",
        "    # Extract the skills checklist for the next phase of analysis\n",
        "    skills_for_analysis = result_obj.required_skills_checklist\n",
        "    solicitation_id_for_analysis = result_obj.solicitation_id\n",
        "\n",
        "    print(f\"\\n✅ Extracted {len(skills_for_analysis)} skills for affinity analysis.\")\n",
        "    print(\"Skills are now ready for the Skill Affinity Engine.\")\n",
        "else:\n",
        "    print(\"⚠️ 'result_obj' not found or is None. Please run the first cell successfully.\")\n",
        "    # Provide a default list to prevent the next cell from failing, or handle as needed\n",
        "    skills_for_analysis = []\n",
        "    solicitation_id_for_analysis = \"SOL_ERROR\""
      ],
      "metadata": {
        "id": "eop1zaiqXooh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "class SkillAffinityEngine:\n",
        "    \"\"\"\n",
        "    Phase 1: Core Analysis - Calculates affinity between researchers and required skills.\n",
        "    \"\"\"\n",
        "    def __init__(self, datastore_path=\"/content/drive/My Drive/datastore/\"):\n",
        "        self.datastore_path = datastore_path\n",
        "        self.model = None\n",
        "        self.metadata_df = None\n",
        "        self.embeddings_array = None\n",
        "        self.embedding_index = None\n",
        "        self.researcher_index = None\n",
        "        self.datastore_info = None\n",
        "\n",
        "    def load_datastore(self):\n",
        "        \"\"\"Load the complete researcher profile datastore.\"\"\"\n",
        "        print(\"📂 Loading Researcher Profile Datastore...\")\n",
        "        try:\n",
        "            self.metadata_df = pd.read_parquet(f\"{self.datastore_path}researcher_profiles_metadata.parquet\")\n",
        "            self.embeddings_array = np.load(f\"{self.datastore_path}researcher_embeddings.npy\")\n",
        "            with open(f\"{self.datastore_path}embedding_index.json\", 'r') as f: self.embedding_index = json.load(f)\n",
        "            with open(f\"{self.datastore_path}researcher_index.json\", 'r') as f: self.researcher_index = json.load(f)\n",
        "            with open(f\"{self.datastore_path}datastore_info.json\", 'r') as f: self.datastore_info = json.load(f)\n",
        "            print(f\"🎯 Datastore ready: {self.metadata_df['researcher_id'].nunique()} researchers, {len(self.metadata_df)} papers\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Failed to load datastore: {e}\")\n",
        "\n",
        "    def load_model(self, model_name='all-MiniLM-L6-v2'):\n",
        "        \"\"\"Load the sentence transformer model.\"\"\"\n",
        "        print(f\"🤖 Loading sentence transformer model: {model_name}\")\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        print(f\"✅ Model loaded.\")\n",
        "\n",
        "    def embed_skills(self, skills_checklist):\n",
        "        \"\"\"Embed each skill phrase.\"\"\"\n",
        "        if self.model is None: self.load_model()\n",
        "        print(f\"🧠 Embedding {len(skills_checklist)} skills...\")\n",
        "        skill_embeddings = self.model.encode(skills_checklist, show_progress_bar=True)\n",
        "        print(f\"✅ Created skill embeddings: {skill_embeddings.shape}\")\n",
        "        return skill_embeddings\n",
        "\n",
        "    def get_researcher_data(self, researcher_id):\n",
        "        \"\"\"Get data for a specific researcher.\"\"\"\n",
        "        work_ids = self.researcher_index.get(researcher_id, [])\n",
        "        positions = [self.embedding_index[wid] for wid in work_ids if wid in self.embedding_index]\n",
        "        if not positions: return np.array([]), [], []\n",
        "        paper_embeddings = self.embeddings_array[positions]\n",
        "        paper_metadata = self.metadata_df[self.metadata_df['work_id'].isin(work_ids)]\n",
        "        weight_mapping = dict(zip(paper_metadata['work_id'], paper_metadata['recency_weight']))\n",
        "        recency_weights = np.array([weight_mapping.get(wid, 0.0) for wid in work_ids if wid in self.embedding_index])\n",
        "        return paper_embeddings, work_ids, recency_weights\n",
        "\n",
        "    def calculate_skill_affinity_score(self, paper_embeddings, skill_embedding, recency_weights):\n",
        "        \"\"\"Calculate affinity score for one researcher against one skill.\"\"\"\n",
        "        if len(paper_embeddings) == 0: return 0.0\n",
        "        cosine_sims = cosine_similarity(paper_embeddings, skill_embedding.reshape(1, -1)).flatten()\n",
        "        max_weighted_sim = np.max(cosine_sims * recency_weights)\n",
        "        return np.clip(max_weighted_sim * 100, 0, 100)\n",
        "\n",
        "    def create_affinity_matrix(self, skills_checklist, solicitation_id=None):\n",
        "        \"\"\"Create the complete affinity matrix.\"\"\"\n",
        "        print(\"🎯 Creating Affinity Matrix...\")\n",
        "        print(\"=\" * 50)\n",
        "        if self.metadata_df is None: self.load_datastore()\n",
        "\n",
        "        # --- FIX: Check for empty skills_checklist ---\n",
        "        if not skills_checklist:\n",
        "            raise ValueError(\"Skills checklist is empty. Cannot create affinity matrix.\")\n",
        "\n",
        "        skill_embeddings = self.embed_skills(skills_checklist)\n",
        "        unique_researchers = list(self.researcher_index.keys())\n",
        "        print(f\"📊 Processing {len(unique_researchers)} researchers × {len(skills_checklist)} skills\")\n",
        "        affinity_matrix = np.zeros((len(unique_researchers), len(skills_checklist)))\n",
        "\n",
        "        for i, researcher_id in enumerate(tqdm(unique_researchers, desc=\"Processing researchers\")):\n",
        "            paper_embeddings, _, recency_weights = self.get_researcher_data(researcher_id)\n",
        "            if len(paper_embeddings) == 0: continue\n",
        "            for j, skill_embedding in enumerate(skill_embeddings):\n",
        "                affinity_matrix[i, j] = self.calculate_skill_affinity_score(paper_embeddings, skill_embedding, recency_weights)\n",
        "\n",
        "        researcher_names = [self.metadata_df[self.metadata_df['researcher_id'] == rid].iloc[0]['researcher_name'] for rid in unique_researchers]\n",
        "        skill_columns = [f\"Skill_{i+1:02d}: {skill[:50]}\" for i, skill in enumerate(skills_checklist)]\n",
        "        affinity_df = pd.DataFrame(affinity_matrix, index=researcher_names, columns=skill_columns)\n",
        "        print(f\"✅ Affinity Matrix created: {affinity_df.shape}\")\n",
        "        return affinity_df, unique_researchers, skills_checklist\n",
        "\n",
        "    def analyze_affinity_matrix(self, affinity_df, skills_checklist):\n",
        "        \"\"\"Provide analysis on the affinity matrix.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60 + \"\\n📊 AFFINITY MATRIX ANALYSIS\\n\" + \"=\"*60)\n",
        "        print(f\"📏 Matrix dimensions: {affinity_df.shape[0]} researchers × {affinity_df.shape[1]} skills\")\n",
        "        print(f\"📈 Score range: {affinity_df.values.min():.2f} - {affinity_df.values.max():.2f}\")\n",
        "        print(f\"📊 Mean affinity score: {affinity_df.values.mean():.2f}\")\n",
        "        researcher_avg_scores = affinity_df.mean(axis=1).sort_values(ascending=False)\n",
        "        print(f\"\\n🏆 Top 5 Researchers (by average affinity):\\n{researcher_avg_scores.head().to_string(float_format='%.2f')}\")\n",
        "        skill_avg_scores = affinity_df.mean(axis=0).sort_values()\n",
        "        print(f\"\\n🎯 Most Challenging Skills (lowest average affinity):\")\n",
        "        for skill_col, score in skill_avg_scores.head().items():\n",
        "            original_skill_index = int(skill_col.split('_')[1].split(':')[0]) - 1\n",
        "            print(f\"   - {skills_checklist[original_skill_index][:60]}...: {score:.2f}\")\n",
        "\n",
        "\n",
        "def main_affinity_analysis(skills_checklist, solicitation_id):\n",
        "    \"\"\"Main function to run the affinity analysis.\"\"\"\n",
        "    print(\"\\n🎯 SKILL AFFINITY ENGINE - PHASE 1 CORE ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    engine = SkillAffinityEngine()\n",
        "\n",
        "    # Run the full pipeline\n",
        "    affinity_df, unique_researchers, skills_list = engine.create_affinity_matrix(\n",
        "        skills_checklist, solicitation_id\n",
        "    )\n",
        "    engine.analyze_affinity_matrix(affinity_df, skills_list)\n",
        "    return affinity_df\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. MAIN EXECUTION FOR AFFINITY ANALYSIS\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure the previous cells have run and skills_for_analysis is available\n",
        "    if 'skills_for_analysis' in locals() and skills_for_analysis:\n",
        "        print(\"Running Skill Affinity Engine with extracted skills...\")\n",
        "        try:\n",
        "            # Pass the extracted skills and ID to the analysis function\n",
        "            affinity_matrix = main_affinity_analysis(skills_for_analysis, solicitation_id_for_analysis)\n",
        "            print(f\"\\n📊 Sample of Affinity Matrix:\")\n",
        "            print(affinity_matrix.iloc[:5, :5])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ An error occurred during affinity analysis: {e}\")\n",
        "    else:\n",
        "        print(\"⚠️ Cannot run affinity analysis because the skills checklist is empty or not defined.\")\n",
        "        print(\"Please run the first two cells successfully to extract skills from the PDF.\")"
      ],
      "metadata": {
        "id": "qbMJcu05xUPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from datetime import datetime\n",
        "import anthropic\n",
        "from google.colab import userdata\n",
        "from typing import List, Dict, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class DreamTeamAssembler:\n",
        "    \"\"\"\n",
        "    Phase 2: Dream Team Assembly & Strategic Output\n",
        "\n",
        "    Implements the greedy algorithm to select optimal research teams and generates\n",
        "    comprehensive strategic reports using AI analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.claude_client = None\n",
        "        self.setup_claude_api()\n",
        "\n",
        "    def setup_claude_api(self):\n",
        "        \"\"\"Initialize Claude API client for gap analysis.\"\"\"\n",
        "        try:\n",
        "            api_key = userdata.get('ANTHROPIC_API_KEY')\n",
        "            self.claude_client = anthropic.Anthropic(api_key=api_key)\n",
        "            print(\"✅ Claude API client initialized for gap analysis\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Claude API setup failed: {e}\")\n",
        "            print(\"Gap analysis will be limited without API access\")\n",
        "\n",
        "    def load_affinity_matrix(self, csv_path, metadata_path=None):\n",
        "        \"\"\"\n",
        "        Load the affinity matrix and associated metadata.\n",
        "\n",
        "        Args:\n",
        "            csv_path (str): Path to affinity matrix CSV\n",
        "            metadata_path (str): Optional path to metadata JSON\n",
        "\n",
        "        Returns:\n",
        "            tuple: (affinity_df, metadata)\n",
        "        \"\"\"\n",
        "        print(f\"📊 Loading affinity matrix from: {csv_path}\")\n",
        "\n",
        "        # Load the matrix\n",
        "        affinity_df = pd.read_csv(csv_path, index_col=0)\n",
        "        print(f\"✅ Loaded matrix: {affinity_df.shape[0]} researchers × {affinity_df.shape[1]} skills\")\n",
        "\n",
        "        # Load metadata if available\n",
        "        metadata = None\n",
        "        if metadata_path:\n",
        "            try:\n",
        "                with open(metadata_path, 'r') as f:\n",
        "                    metadata = json.load(f)\n",
        "                print(f\"✅ Loaded metadata\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Could not load metadata: {e}\")\n",
        "\n",
        "        return affinity_df, metadata\n",
        "\n",
        "    def calculate_team_coverage(self, affinity_df, team_indices):\n",
        "        \"\"\"\n",
        "        Calculate team coverage scores for all skills.\n",
        "\n",
        "        Args:\n",
        "            affinity_df (pd.DataFrame): Affinity matrix\n",
        "            team_indices (list): Indices of selected team members\n",
        "\n",
        "        Returns:\n",
        "            tuple: (skill_coverages, overall_coverage_score)\n",
        "        \"\"\"\n",
        "        if not team_indices:\n",
        "            return [], 0.0\n",
        "\n",
        "        # Get affinity scores for team members\n",
        "        team_affinities = affinity_df.iloc[team_indices]\n",
        "\n",
        "        # For each skill, take the maximum affinity among team members\n",
        "        skill_coverages = team_affinities.max(axis=0).values\n",
        "\n",
        "        # Overall team coverage score is the average\n",
        "        overall_coverage_score = np.mean(skill_coverages)\n",
        "\n",
        "        return skill_coverages, overall_coverage_score\n",
        "\n",
        "    def calculate_marginal_gain(self, affinity_df, current_team_indices, candidate_index):\n",
        "        \"\"\"\n",
        "        Calculate marginal gain of adding a candidate to the current team.\n",
        "\n",
        "        Args:\n",
        "            affinity_df (pd.DataFrame): Affinity matrix\n",
        "            current_team_indices (list): Current team member indices\n",
        "            candidate_index (int): Index of candidate researcher\n",
        "\n",
        "        Returns:\n",
        "            float: Marginal gain in coverage score\n",
        "        \"\"\"\n",
        "        # Current team coverage\n",
        "        _, current_coverage = self.calculate_team_coverage(affinity_df, current_team_indices)\n",
        "\n",
        "        # New team coverage with candidate added\n",
        "        new_team_indices = current_team_indices + [candidate_index]\n",
        "        _, new_coverage = self.calculate_team_coverage(affinity_df, new_team_indices)\n",
        "\n",
        "        # Marginal gain\n",
        "        marginal_gain = new_coverage - current_coverage\n",
        "\n",
        "        return marginal_gain\n",
        "\n",
        "    def dream_team_greedy_algorithm(self, affinity_df, min_team_size=2, max_team_size=4):\n",
        "        \"\"\"\n",
        "        Implement the Dream Team Greedy Algorithm.\n",
        "\n",
        "        Args:\n",
        "            affinity_df (pd.DataFrame): Affinity matrix\n",
        "            min_team_size (int): Minimum team size\n",
        "            max_team_size (int): Maximum team size\n",
        "\n",
        "        Returns:\n",
        "            tuple: (selected_team_indices, selection_history)\n",
        "        \"\"\"\n",
        "        print(\"🎯 Running Dream Team Greedy Algorithm...\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        n_researchers = len(affinity_df)\n",
        "        selected_indices = []\n",
        "        selection_history = []\n",
        "\n",
        "        # Step 1: Select the best overall researcher (likely PI)\n",
        "        researcher_avg_scores = affinity_df.mean(axis=1)\n",
        "        best_researcher_idx = researcher_avg_scores.idxmax()\n",
        "        best_researcher_pos = affinity_df.index.get_loc(best_researcher_idx)\n",
        "\n",
        "        selected_indices.append(best_researcher_pos)\n",
        "        _, initial_coverage = self.calculate_team_coverage(affinity_df, selected_indices)\n",
        "\n",
        "        selection_history.append({\n",
        "            'step': 1,\n",
        "            'action': 'initial_selection',\n",
        "            'researcher_idx': best_researcher_pos,\n",
        "            'researcher_name': affinity_df.index[best_researcher_pos],\n",
        "            'reason': 'Highest average affinity score (likely PI)',\n",
        "            'team_coverage': initial_coverage,\n",
        "            'marginal_gain': initial_coverage\n",
        "        })\n",
        "\n",
        "        print(f\"🏆 Step 1 - PI Selection: {affinity_df.index[best_researcher_pos]}\")\n",
        "        print(f\"    Initial coverage: {initial_coverage:.2f}\")\n",
        "\n",
        "        # Steps 2-4: Iteratively add researchers with maximum marginal gain\n",
        "        for step in range(2, max_team_size + 1):\n",
        "            best_candidate_idx = None\n",
        "            best_marginal_gain = -1\n",
        "            candidate_gains = []\n",
        "\n",
        "            # Evaluate all remaining researchers\n",
        "            for candidate_idx in range(n_researchers):\n",
        "                if candidate_idx in selected_indices:\n",
        "                    continue  # Skip already selected researchers\n",
        "\n",
        "                marginal_gain = self.calculate_marginal_gain(\n",
        "                    affinity_df, selected_indices, candidate_idx\n",
        "                )\n",
        "                candidate_gains.append((candidate_idx, marginal_gain))\n",
        "\n",
        "                if marginal_gain > best_marginal_gain:\n",
        "                    best_marginal_gain = marginal_gain\n",
        "                    best_candidate_idx = candidate_idx\n",
        "\n",
        "            # Add the best candidate if marginal gain is positive and we haven't reached min size\n",
        "            # Or if marginal gain is significant enough and we're expanding beyond min size\n",
        "            should_add = False\n",
        "            if len(selected_indices) < min_team_size:\n",
        "                should_add = True  # Must reach minimum team size\n",
        "            elif best_marginal_gain > 0.5:  # Only add if significant improvement\n",
        "                should_add = True\n",
        "\n",
        "            if should_add and best_candidate_idx is not None:\n",
        "                selected_indices.append(best_candidate_idx)\n",
        "                _, new_coverage = self.calculate_team_coverage(affinity_df, selected_indices)\n",
        "\n",
        "                selection_history.append({\n",
        "                    'step': step,\n",
        "                    'action': 'add_member',\n",
        "                    'researcher_idx': best_candidate_idx,\n",
        "                    'researcher_name': affinity_df.index[best_candidate_idx],\n",
        "                    'reason': f'Maximum marginal gain (+{best_marginal_gain:.2f})',\n",
        "                    'team_coverage': new_coverage,\n",
        "                    'marginal_gain': best_marginal_gain\n",
        "                })\n",
        "\n",
        "                print(f\"✅ Step {step} - Added: {affinity_df.index[best_candidate_idx]}\")\n",
        "                print(f\"    Marginal gain: +{best_marginal_gain:.2f}, New coverage: {new_coverage:.2f}\")\n",
        "            else:\n",
        "                print(f\"🛑 Step {step} - Stopping: No significant marginal gain (best: +{best_marginal_gain:.2f})\")\n",
        "                break\n",
        "\n",
        "        print(f\"\\n🎯 Final Dream Team: {len(selected_indices)} researchers\")\n",
        "        print(f\"📊 Final team coverage: {self.calculate_team_coverage(affinity_df, selected_indices)[1]:.2f}\")\n",
        "\n",
        "        return selected_indices, selection_history\n",
        "\n",
        "    def generate_coverage_report(self, affinity_df, team_indices, skills_list):\n",
        "        \"\"\"\n",
        "        Generate detailed coverage report for the selected team.\n",
        "\n",
        "        Args:\n",
        "            affinity_df (pd.DataFrame): Affinity matrix\n",
        "            team_indices (list): Selected team member indices\n",
        "            skills_list (list): List of skill descriptions\n",
        "\n",
        "        Returns:\n",
        "            dict: Comprehensive coverage report\n",
        "        \"\"\"\n",
        "        print(\"📋 Generating Coverage Report...\")\n",
        "\n",
        "        # Calculate coverage\n",
        "        skill_coverages, overall_coverage = self.calculate_team_coverage(affinity_df, team_indices)\n",
        "\n",
        "        # Team member details\n",
        "        team_members = []\n",
        "        for idx in team_indices:\n",
        "            researcher_name = affinity_df.index[idx]\n",
        "            researcher_scores = affinity_df.iloc[idx].values\n",
        "            avg_score = np.mean(researcher_scores)\n",
        "            max_score = np.max(researcher_scores)\n",
        "\n",
        "            # Find top skills for this researcher\n",
        "            top_skill_indices = np.argsort(researcher_scores)[-3:][::-1]  # Top 3\n",
        "            top_skills = [(skills_list[i], researcher_scores[i]) for i in top_skill_indices]\n",
        "\n",
        "            team_members.append({\n",
        "                'name': researcher_name,\n",
        "                'index': idx,\n",
        "                'avg_affinity': avg_score,\n",
        "                'max_affinity': max_score,\n",
        "                'top_skills': top_skills,\n",
        "                'all_scores': researcher_scores.tolist()\n",
        "            })\n",
        "\n",
        "        # Skill coverage analysis\n",
        "        skill_analysis = []\n",
        "        for i, (skill, coverage) in enumerate(zip(skills_list, skill_coverages)):\n",
        "            # Find which team member provides this coverage\n",
        "            team_scores_for_skill = [member['all_scores'][i] for member in team_members]\n",
        "            best_member_idx = np.argmax(team_scores_for_skill)\n",
        "            best_member = team_members[best_member_idx]\n",
        "\n",
        "            coverage_level = 'High' if coverage >= 70 else 'Medium' if coverage >= 40 else 'Low'\n",
        "\n",
        "            skill_analysis.append({\n",
        "                'skill': skill,\n",
        "                'coverage_score': coverage,\n",
        "                'coverage_level': coverage_level,\n",
        "                'primary_expert': best_member['name'],\n",
        "                'expert_score': team_scores_for_skill[best_member_idx]\n",
        "            })\n",
        "\n",
        "        # Coverage statistics\n",
        "        high_coverage_count = sum(1 for s in skill_analysis if s['coverage_level'] == 'High')\n",
        "        medium_coverage_count = sum(1 for s in skill_analysis if s['coverage_level'] == 'Medium')\n",
        "        low_coverage_count = sum(1 for s in skill_analysis if s['coverage_level'] == 'Low')\n",
        "\n",
        "        coverage_report = {\n",
        "            'team_size': len(team_members),\n",
        "            'overall_coverage_score': overall_coverage,\n",
        "            'team_members': team_members,\n",
        "            'skill_analysis': skill_analysis,\n",
        "            'coverage_statistics': {\n",
        "                'high_coverage_skills': high_coverage_count,\n",
        "                'medium_coverage_skills': medium_coverage_count,\n",
        "                'low_coverage_skills': low_coverage_count,\n",
        "                'coverage_distribution': {\n",
        "                    'high_pct': 100 * high_coverage_count / len(skills_list),\n",
        "                    'medium_pct': 100 * medium_coverage_count / len(skills_list),\n",
        "                    'low_pct': 100 * low_coverage_count / len(skills_list)\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        print(f\"✅ Coverage report generated\")\n",
        "        print(f\"📊 Overall coverage: {overall_coverage:.2f}\")\n",
        "        print(f\"🔥 High coverage skills: {high_coverage_count}/{len(skills_list)}\")\n",
        "\n",
        "        return coverage_report\n",
        "\n",
        "    def format_gap_analysis_prompt(self, coverage_report, skills_list, solicitation_data=None):\n",
        "        \"\"\"\n",
        "        Format the prompt for Claude API gap analysis.\n",
        "\n",
        "        Args:\n",
        "            coverage_report (dict): Team coverage analysis\n",
        "            skills_list (list): Required skills\n",
        "            solicitation_data (dict): Original solicitation information\n",
        "\n",
        "        Returns:\n",
        "            str: Formatted prompt for Claude API\n",
        "        \"\"\"\n",
        "\n",
        "        # Team summary\n",
        "        team_summary = f\"PROPOSED RESEARCH TEAM ({coverage_report['team_size']} members):\\n\"\n",
        "        for i, member in enumerate(coverage_report['team_members']):\n",
        "            role = \"Principal Investigator (PI)\" if i == 0 else f\"Co-Investigator {i}\"\n",
        "            team_summary += f\"\\n{i+1}. {member['name']} - {role}\\n\"\n",
        "            team_summary += f\"   Average Affinity: {member['avg_affinity']:.2f}\\n\"\n",
        "            team_summary += f\"   Top Expertise Areas:\\n\"\n",
        "            for skill, score in member['top_skills']:\n",
        "                team_summary += f\"     • {skill}: {score:.1f}\\n\"\n",
        "\n",
        "        # Coverage analysis\n",
        "        coverage_summary = f\"\\nTEAM COVERAGE ANALYSIS:\\n\"\n",
        "        coverage_summary += f\"Overall Team Coverage Score: {coverage_report['overall_coverage_score']:.2f}/100\\n\\n\"\n",
        "\n",
        "        coverage_summary += \"HIGH COVERAGE SKILLS (≥70):\\n\"\n",
        "        for skill in coverage_report['skill_analysis']:\n",
        "            if skill['coverage_level'] == 'High':\n",
        "                coverage_summary += f\"• {skill['skill']}: {skill['coverage_score']:.1f} (Expert: {skill['primary_expert']})\\n\"\n",
        "\n",
        "        coverage_summary += \"\\nMEDIUM COVERAGE SKILLS (40-69):\\n\"\n",
        "        for skill in coverage_report['skill_analysis']:\n",
        "            if skill['coverage_level'] == 'Medium':\n",
        "                coverage_summary += f\"• {skill['skill']}: {skill['coverage_score']:.1f} (Expert: {skill['primary_expert']})\\n\"\n",
        "\n",
        "        coverage_summary += \"\\nLOW COVERAGE SKILLS (<40) - POTENTIAL GAPS:\\n\"\n",
        "        for skill in coverage_report['skill_analysis']:\n",
        "            if skill['coverage_level'] == 'Low':\n",
        "                coverage_summary += f\"• {skill['skill']}: {skill['coverage_score']:.1f} (Expert: {skill['primary_expert']})\\n\"\n",
        "\n",
        "        # Solicitation context\n",
        "        solicitation_context = \"\"\n",
        "        if solicitation_data:\n",
        "            solicitation_context = f\"\\nORIGINAL SOLICITATION CONTEXT:\\n\"\n",
        "            solicitation_context += f\"Title: {solicitation_data.get('title', 'N/A')}\\n\"\n",
        "            solicitation_context += f\"Abstract: {solicitation_data.get('abstract', 'N/A')[:500]}...\\n\"\n",
        "\n",
        "        # Main prompt\n",
        "        prompt = f\"\"\"As an expert NSF Program Manager and research strategy consultant, analyze this proposed research team for a competitive grant application.\n",
        "\n",
        "{team_summary}\n",
        "\n",
        "{coverage_summary}\n",
        "\n",
        "{solicitation_context}\n",
        "\n",
        "Please provide a comprehensive strategic analysis covering:\n",
        "\n",
        "1. **TEAM STRENGTHS**: What are the key strengths of this team composition? How do their expertise areas complement each other?\n",
        "\n",
        "2. **COVERAGE GAPS & RISKS**: Analyze the low-coverage skills. Are these critical gaps that could harm competitiveness? Which gaps are most concerning?\n",
        "\n",
        "3. **STRATEGIC RECOMMENDATIONS**:\n",
        "   - Should additional collaborators be recruited for specific gaps?\n",
        "   - How can the team leverage their strengths to compensate for weaknesses?\n",
        "   - What sections of the proposal should each member lead?\n",
        "\n",
        "4. **COMPETITIVE POSITIONING**: How competitive is this team compared to typical NSF applications? What makes them stand out?\n",
        "\n",
        "5. **PROPOSAL STRATEGY**: Provide 3-5 specific, actionable recommendations for structuring their proposal to maximize success.\n",
        "\n",
        "Format your response as a professional strategic report suitable for team planning meetings.\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def generate_gap_analysis(self, coverage_report, skills_list, solicitation_data=None):\n",
        "        \"\"\"\n",
        "        Generate AI-powered gap analysis using Claude API.\n",
        "\n",
        "        Args:\n",
        "            coverage_report (dict): Team coverage analysis\n",
        "            skills_list (list): Required skills list\n",
        "            solicitation_data (dict): Optional solicitation data\n",
        "\n",
        "        Returns:\n",
        "            str: Strategic analysis from Claude API\n",
        "        \"\"\"\n",
        "        if not self.claude_client:\n",
        "            return self._generate_fallback_analysis(coverage_report)\n",
        "\n",
        "        print(\"🤖 Generating strategic analysis with Claude API...\")\n",
        "\n",
        "        try:\n",
        "            prompt = self.format_gap_analysis_prompt(coverage_report, skills_list, solicitation_data)\n",
        "\n",
        "            response = self.claude_client.messages.create(\n",
        "                model=\"claude-3-sonnet-20240229\",\n",
        "                max_tokens=2000,\n",
        "                temperature=0.7,\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            analysis = response.content[0].text\n",
        "            print(\"✅ Strategic analysis generated\")\n",
        "            return analysis\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Claude API analysis failed: {e}\")\n",
        "            return self._generate_fallback_analysis(coverage_report)\n",
        "\n",
        "    def _generate_fallback_analysis(self, coverage_report):\n",
        "        \"\"\"Generate basic analysis when Claude API is unavailable.\"\"\"\n",
        "\n",
        "        analysis = \"STRATEGIC ANALYSIS (Basic Report)\\n\"\n",
        "        analysis += \"=\" * 50 + \"\\n\\n\"\n",
        "\n",
        "        analysis += f\"TEAM OVERVIEW:\\n\"\n",
        "        analysis += f\"Team Size: {coverage_report['team_size']} researchers\\n\"\n",
        "        analysis += f\"Overall Coverage: {coverage_report['overall_coverage_score']:.2f}/100\\n\\n\"\n",
        "\n",
        "        analysis += \"COVERAGE DISTRIBUTION:\\n\"\n",
        "        stats = coverage_report['coverage_statistics']\n",
        "        analysis += f\"High Coverage Skills: {stats['high_coverage_skills']} ({stats['coverage_distribution']['high_pct']:.1f}%)\\n\"\n",
        "        analysis += f\"Medium Coverage Skills: {stats['medium_coverage_skills']} ({stats['coverage_distribution']['medium_pct']:.1f}%)\\n\"\n",
        "        analysis += f\"Low Coverage Skills: {stats['low_coverage_skills']} ({stats['coverage_distribution']['low_pct']:.1f}%)\\n\\n\"\n",
        "\n",
        "        if stats['low_coverage_skills'] > 0:\n",
        "            analysis += \"ATTENTION NEEDED:\\n\"\n",
        "            analysis += f\"The team has {stats['low_coverage_skills']} skills with low coverage. Consider recruiting additional expertise or developing strategic partnerships.\\n\\n\"\n",
        "\n",
        "        analysis += \"RECOMMENDATIONS:\\n\"\n",
        "        analysis += \"• Review low-coverage skills for recruitment opportunities\\n\"\n",
        "        analysis += \"• Leverage high-coverage areas as competitive advantages\\n\"\n",
        "        analysis += \"• Consider collaborative arrangements for gap areas\\n\"\n",
        "\n",
        "        return analysis\n",
        "\n",
        "    def create_strategic_report(self, affinity_df, metadata=None, skills_list=None, solicitation_data=None):\n",
        "        \"\"\"\n",
        "        Main function to create comprehensive strategic report.\n",
        "\n",
        "        Args:\n",
        "            affinity_df (pd.DataFrame): Affinity matrix\n",
        "            metadata (dict): Optional metadata\n",
        "            skills_list (list): Required skills\n",
        "            solicitation_data (dict): Original solicitation data\n",
        "\n",
        "        Returns:\n",
        "            dict: Complete strategic report\n",
        "        \"\"\"\n",
        "        print(\"🚀 CREATING STRATEGIC REPORT\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Extract skills list if not provided\n",
        "        if skills_list is None and metadata:\n",
        "            skills_list = metadata.get('skills_checklist', [])\n",
        "\n",
        "        if skills_list is None:\n",
        "            # Extract from column names\n",
        "            skills_list = [col.split(': ', 1)[1] if ': ' in col else col for col in affinity_df.columns]\n",
        "\n",
        "        # Step 1: Run Dream Team Algorithm\n",
        "        team_indices, selection_history = self.dream_team_greedy_algorithm(affinity_df)\n",
        "\n",
        "        # Step 2: Generate Coverage Report\n",
        "        coverage_report = self.generate_coverage_report(affinity_df, team_indices, skills_list)\n",
        "\n",
        "        # Step 3: Generate Gap Analysis\n",
        "        strategic_analysis = self.generate_gap_analysis(coverage_report, skills_list, solicitation_data)\n",
        "\n",
        "        # Step 4: Compile Strategic Report\n",
        "        strategic_report = {\n",
        "            'report_metadata': {\n",
        "                'generated_at': datetime.now().isoformat(),\n",
        "                'solicitation_id': solicitation_data.get('solicitation_id') if solicitation_data else None,\n",
        "                'analysis_type': 'dream_team_strategic_report'\n",
        "            },\n",
        "            'dream_team': {\n",
        "                'team_indices': team_indices,\n",
        "                'selection_algorithm': 'greedy_marginal_gain',\n",
        "                'selection_history': selection_history\n",
        "            },\n",
        "            'coverage_analysis': coverage_report,\n",
        "            'strategic_analysis': strategic_analysis,\n",
        "            'skills_checklist': skills_list,\n",
        "            'solicitation_context': solicitation_data\n",
        "        }\n",
        "\n",
        "        print(\"✅ Strategic Report Generated!\")\n",
        "        return strategic_report\n",
        "\n",
        "    def save_strategic_report(self, strategic_report, output_path=None):\n",
        "        \"\"\"Save the strategic report to files.\"\"\"\n",
        "\n",
        "        if output_path is None:\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            output_path = f\"strategic_report_{timestamp}\"\n",
        "\n",
        "        # Save complete JSON report\n",
        "        json_path = f\"{output_path}.json\"\n",
        "        with open(json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(strategic_report, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        # Save human-readable text report\n",
        "        text_path = f\"{output_path}.txt\"\n",
        "        with open(text_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(self.format_text_report(strategic_report))\n",
        "\n",
        "        print(f\"💾 Strategic report saved:\")\n",
        "        print(f\"   📄 JSON: {json_path}\")\n",
        "        print(f\"   📝 Text: {text_path}\")\n",
        "\n",
        "        return json_path, text_path\n",
        "\n",
        "    def format_text_report(self, strategic_report):\n",
        "        \"\"\"Format strategic report as human-readable text.\"\"\"\n",
        "\n",
        "        report = \"NSF DREAM TEAM STRATEGIC REPORT\\n\"\n",
        "        report += \"=\" * 60 + \"\\n\\n\"\n",
        "\n",
        "        # Header\n",
        "        metadata = strategic_report['report_metadata']\n",
        "        report += f\"Generated: {metadata['generated_at']}\\n\"\n",
        "        if metadata.get('solicitation_id'):\n",
        "            report += f\"Solicitation ID: {metadata['solicitation_id']}\\n\"\n",
        "        report += \"\\n\"\n",
        "\n",
        "        # Dream Team\n",
        "        report += \"RECOMMENDED DREAM TEAM\\n\"\n",
        "        report += \"-\" * 25 + \"\\n\"\n",
        "\n",
        "        team_members = strategic_report['coverage_analysis']['team_members']\n",
        "        for i, member in enumerate(team_members):\n",
        "            role = \"Principal Investigator (PI)\" if i == 0 else f\"Co-Investigator {i}\"\n",
        "            report += f\"\\n{i+1}. {member['name']} - {role}\\n\"\n",
        "            report += f\"   Average Affinity Score: {member['avg_affinity']:.2f}\\n\"\n",
        "            report += f\"   Primary Expertise:\\n\"\n",
        "            for skill, score in member['top_skills'][:2]:  # Top 2 skills\n",
        "                report += f\"     • {skill}: {score:.1f}\\n\"\n",
        "\n",
        "        # Coverage Summary\n",
        "        coverage = strategic_report['coverage_analysis']\n",
        "        report += f\"\\nTEAM COVERAGE SUMMARY\\n\"\n",
        "        report += \"-\" * 22 + \"\\n\"\n",
        "        report += f\"Overall Coverage Score: {coverage['overall_coverage_score']:.2f}/100\\n\"\n",
        "\n",
        "        stats = coverage['coverage_statistics']\n",
        "        report += f\"High Coverage Skills: {stats['high_coverage_skills']} ({stats['coverage_distribution']['high_pct']:.1f}%)\\n\"\n",
        "        report += f\"Medium Coverage Skills: {stats['medium_coverage_skills']} ({stats['coverage_distribution']['medium_pct']:.1f}%)\\n\"\n",
        "        report += f\"Low Coverage Skills: {stats['low_coverage_skills']} ({stats['coverage_distribution']['low_pct']:.1f}%)\\n\"\n",
        "\n",
        "        # Strategic Analysis\n",
        "        report += f\"\\nSTRATEGIC ANALYSIS\\n\"\n",
        "        report += \"-\" * 18 + \"\\n\"\n",
        "        report += strategic_report['strategic_analysis']\n",
        "\n",
        "        return report\n",
        "\n",
        "    def display_summary(self, strategic_report):\n",
        "        \"\"\"Display a summary of the strategic report.\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"📋 DREAM TEAM STRATEGIC REPORT SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Team overview\n",
        "        team_members = strategic_report['coverage_analysis']['team_members']\n",
        "        print(f\"🏆 Recommended Team Size: {len(team_members)}\")\n",
        "\n",
        "        for i, member in enumerate(team_members):\n",
        "            role = \"PI\" if i == 0 else f\"Co-I {i}\"\n",
        "            print(f\"   {i+1}. {member['name']} ({role}) - Avg Score: {member['avg_affinity']:.2f}\")\n",
        "\n",
        "        # Coverage stats\n",
        "        coverage = strategic_report['coverage_analysis']['coverage_statistics']\n",
        "        print(f\"\\n📊 Coverage Distribution:\")\n",
        "        print(f\"   🔥 High Coverage: {coverage['high_coverage_skills']} skills ({coverage['coverage_distribution']['high_pct']:.1f}%)\")\n",
        "        print(f\"   📊 Medium Coverage: {coverage['medium_coverage_skills']} skills ({coverage['coverage_distribution']['medium_pct']:.1f}%)\")\n",
        "        print(f\"   ⚠️  Low Coverage: {coverage['low_coverage_skills']} skills ({coverage['coverage_distribution']['low_pct']:.1f}%)\")\n",
        "\n",
        "        overall_score = strategic_report['coverage_analysis']['overall_coverage_score']\n",
        "        print(f\"\\n🎯 Overall Team Coverage Score: {overall_score:.2f}/100\")\n",
        "\n",
        "        if overall_score >= 70:\n",
        "            print(\"✅ EXCELLENT: Strong team with high coverage\")\n",
        "        elif overall_score >= 50:\n",
        "            print(\"✅ GOOD: Solid team with room for strategic partnerships\")\n",
        "        else:\n",
        "            print(\"⚠️ NEEDS WORK: Consider additional recruitment or collaborations\")\n",
        "\n",
        "def main_dream_team_analysis(affinity_csv_path, metadata_json_path=None, solicitation_json_path=None):\n",
        "    \"\"\"\n",
        "    Main function to run complete Dream Team analysis.\n",
        "\n",
        "    Args:\n",
        "        affinity_csv_path (str): Path to affinity matrix CSV\n",
        "        metadata_json_path (str): Path to affinity metadata JSON\n",
        "        solicitation_json_path (str): Path to original solicitation JSON\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"🎯 DREAM TEAM ASSEMBLER - PHASE 2 STRATEGIC OUTPUT\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Initialize assembler\n",
        "    assembler = DreamTeamAssembler()\n",
        "\n",
        "    # Load affinity matrix\n",
        "    affinity_df, affinity_metadata = assembler.load_affinity_matrix(affinity_csv_path, metadata_json_path)\n",
        "\n",
        "    # Load solicitation data if available\n",
        "    solicitation_data = None\n",
        "    if solicitation_json_path:\n",
        "        try:\n",
        "            with open(solicitation_json_path, 'r') as f:\n",
        "                solicitation_data = json.load(f)\n",
        "            print(f\"✅ Loaded solicitation data\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Could not load solicitation data: {e}\")\n",
        "\n",
        "    # Extract skills list\n",
        "    skills_list = None\n",
        "    if affinity_metadata and 'skills_checklist' in affinity_metadata:\n",
        "        skills_list = affinity_metadata['skills_checklist']\n",
        "    elif solicitation_data and 'required_skills_checklist' in solicitation_data:\n",
        "        skills_list = solicitation_data['required_skills_checklist']\n",
        "\n",
        "    # Create strategic report\n",
        "    strategic_report = assembler.create_strategic_report(\n",
        "        affinity_df=affinity_df,\n",
        "        metadata=affinity_metadata,\n",
        "        skills_list=skills_list,\n",
        "        solicitation_data=solicitation_data\n",
        "    )\n",
        "\n",
        "    # Save report\n",
        "    json_path, text_path = assembler.save_strategic_report(strategic_report)\n",
        "\n",
        "    # Display summary\n",
        "    assembler.display_summary(strategic_report)\n",
        "\n",
        "    print(f\"\\n✅ Dream Team Analysis Complete!\")\n",
        "    print(f\"📄 Full report available at: {text_path}\")\n",
        "\n",
        "    return strategic_report\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage - update paths as needed\n",
        "    AFFINITY_CSV = \"/content/drive/MyDrive/datastore/affinity_matrix_SOL_EXAMPLE1.csv\"\n",
        "    AFFINITY_METADATA = \"/content/drive/MyDrive/datastore/affinity_matrix_SOL_EXAMPLE1_metadata1.json\"\n",
        "    SOLICITATION_JSON = \"NSF 24-569_ Mathematical Foundations of Artificial Intelligence (MFAI) _ NSF - National Science Foundation_analysis.json\"  # Optional\n",
        "\n",
        "    try:\n",
        "        report = main_dream_team_analysis(\n",
        "            affinity_csv_path=AFFINITY_CSV,\n",
        "            metadata_json_path=AFFINITY_METADATA,\n",
        "            solicitation_json_path=SOLICITATION_JSON\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        print(\"Please verify file paths and try again\")"
      ],
      "metadata": {
        "id": "tW3A72pyyts1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Researcher Profile Datastore: Built system to extract top 50 Texas State researchers + Tahir Ekin, generating embeddings for all papers using all-MiniLM-L6-v2 sentence transformer model with recency weights Wt = max(0, 1-(CurrentYear-PublicationYear)/10).\n",
        "\n",
        "Storage Structure: Created indexed datastore in Google Drive with researcher_profiles_metadata.parquet (paper metadata), researcher_embeddings.npy (384-dim vectors), embedding_index.json (work_id→position), researcher_index.json (researcher_id→work_ids).\n",
        "\n",
        "PDF Solicitation Processor: Hybrid system using PyMuPDF extraction + Claude API (narrative skills) + OpenAlex BERT classifier (formal topics), with fusion logic to create final Required Skills Checklist.\n",
        "\n",
        "Skill Affinity Engine: Implements mathematical formula SkillAffinityScore(R,Sk) = max(cosine_similarity(paper,skill) × recency_weight) × 100 for every researcher×skill combination.\n",
        "\n",
        "Affinity Matrix: 51 researchers × 17 skills matrix with percentage scores (0-100), saved as CSV with metadata JSON for tracking and analysis.\n",
        "Dream Team Greedy Algorithm: Selects optimal 2-4 researcher teams by iteratively choosing candidates with maximum marginal gain in team coverage scores.\n",
        "\n",
        "Coverage Analysis: Calculates Team Coverage Score (average of max affinity per skill), categorizes skills as High/Medium/Low coverage, identifies primary experts per skill area.\n",
        "\n",
        "Strategic Report Generation: Uses Claude API to analyze team composition, coverage gaps, competitive positioning, and proposal strategy recommendations.\n",
        "End-to-End Pipeline: PDF→Skills Extraction→Affinity Calculation→Team Selection→Strategic Analysis, all integrated with proper error handling and fallback methods.\n",
        "\n",
        "Key Files: Researcher datastore (5 files), solicitation JSON objects, affinity matrices with metadata, and comprehensive strategic reports (JSON + human-readable text formats)."
      ],
      "metadata": {
        "id": "mENmaWcP0xcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V2 with better file management\n"
      ],
      "metadata": {
        "id": "lQc-c8qela63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Cell 1: PDF Processing & Run Initialization\n",
        "# ==============================================================================\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from google.colab import drive, userdata\n",
        "from transformers import pipeline\n",
        "import anthropic\n",
        "from dataclasses import dataclass, asdict\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "# --- Only change this section for a new analysis ---\n",
        "DRIVE_MOUNT_PATH = '/content/drive'\n",
        "DATASTORE_PATH = \"/content/drive/MyDrive/datastore/\"\n",
        "# This is the ONLY line you need to change to process a new file.\n",
        "PDF_FILE_PATH = \"/content/drive/MyDrive/datastore/NSF 25-530: Collaborations in Artificial Intelligence and Geosciences (CAIG) | NSF - National Science Foundation.pdf\"\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "@dataclass\n",
        "class StructuredSolicitationObject:\n",
        "    \"\"\"\n",
        "    Structured object containing solicitation metadata and required skills.\n",
        "    \"\"\"\n",
        "    # Metadata\n",
        "    solicitation_id: str\n",
        "    title: str\n",
        "    abstract: str\n",
        "    processed_at: str\n",
        "    pdf_filename: str\n",
        "\n",
        "    # Skills from both paths\n",
        "    narrative_skills: List[str]  # From Claude API (Path A)\n",
        "    formal_topics: List[Dict]    # From OpenAlex classifier (Path B)\n",
        "\n",
        "    # Final combined checklist\n",
        "    required_skills_checklist: List[str]\n",
        "\n",
        "    # Processing details\n",
        "    text_length: int\n",
        "    processing_method: str = \"hybrid_deconstruction\"\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n",
        "        return asdict(self)\n",
        "\n",
        "    def to_json(self, filepath: str):\n",
        "        \"\"\"Save to JSON file.\"\"\"\n",
        "        with open(filepath, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.to_dict(), f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. PDF SOLICITATION PROCESSOR CLASS\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "class PDFSolicitationProcessor:\n",
        "    \"\"\"\n",
        "    Processes PDF solicitations from a file path to extract required skills.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.claude_client = None\n",
        "        self.topic_classifier = None\n",
        "        self.setup_models()\n",
        "\n",
        "    def setup_models(self):\n",
        "        \"\"\"Initialize Claude API client and OpenAlex topic classifier.\"\"\"\n",
        "        print(\"Setting up models...\")\n",
        "        try:\n",
        "            api_key = userdata.get('ANTHROPIC_API_KEY')\n",
        "            self.claude_client = anthropic.Anthropic(api_key=api_key)\n",
        "            print(\"✅ Claude API client initialized\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Claude API setup failed: {e}\")\n",
        "\n",
        "        try:\n",
        "            print(\"Loading OpenAlex topic classifier...\")\n",
        "            self.topic_classifier = pipeline(\n",
        "                \"text-classification\",\n",
        "                model=\"OpenAlex/bert-base-multilingual-cased-finetuned-openalex-topic-classification-title-abstract\"\n",
        "            )\n",
        "            print(\"✅ OpenAlex topic classifier loaded\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Topic classifier setup failed: {e}\")\n",
        "\n",
        "    def _extract_text_from_pdf(self, filepath: str) -> Tuple[str, str, str]:\n",
        "        \"\"\"Extracts text content from a PDF given a file path.\"\"\"\n",
        "        if not os.path.exists(filepath):\n",
        "            raise FileNotFoundError(f\"The file was not found at: {filepath}\")\n",
        "\n",
        "        filename = os.path.basename(filepath)\n",
        "        print(f\"📄 Processing: {filename}\")\n",
        "\n",
        "        try:\n",
        "            doc = fitz.open(filepath)\n",
        "            full_text = \"\".join([page.get_text() for page in doc])\n",
        "            doc.close()\n",
        "\n",
        "            if not full_text.strip():\n",
        "                 raise ValueError(\"Extracted text is empty. The PDF might be an image.\")\n",
        "\n",
        "            title, abstract = self._extract_title_and_abstract(full_text, filename)\n",
        "            print(f\"✅ Extracted {len(full_text)} characters from PDF.\")\n",
        "            return filename, title, abstract\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error extracting text from PDF '{filename}': {e}\")\n",
        "            raise\n",
        "\n",
        "    def _extract_title_and_abstract(self, full_text: str, filename: str) -> Tuple[str, str]:\n",
        "        \"\"\"Extract title and abstract from full text using heuristics.\"\"\"\n",
        "        lines = [line.strip() for line in full_text.split('\\n') if line.strip()]\n",
        "        title = filename.replace('.pdf', '').replace('_', ' ').replace('-', ' ')\n",
        "        for line in lines[:15]: # Check more lines for title\n",
        "            if 20 < len(line) < 250 and not line.isupper(): # Avoid all-caps headers\n",
        "                title = line\n",
        "                break\n",
        "\n",
        "        abstract = \"\"\n",
        "        abstract_started = False\n",
        "        for line in lines:\n",
        "            line_lower = line.lower()\n",
        "            if not abstract_started and any(marker in line_lower for marker in ['abstract', 'summary', 'overview']):\n",
        "                abstract_started = True\n",
        "                if len(line) > len('abstract') + 10: abstract += line.split(maxsplit=1)[1]\n",
        "                continue\n",
        "            if abstract_started:\n",
        "                abstract += \" \" + line\n",
        "                if len(abstract) > 1500 or any(marker in line_lower for marker in ['introduction', 'background']):\n",
        "                    break\n",
        "        if not abstract: abstract = ' '.join(lines[:10]) # Fallback\n",
        "        return title.strip(), abstract.strip()[:2000] # Increased limit\n",
        "\n",
        "    def extract_narrative_skills_claude(self, text: str) -> List[str]:\n",
        "        \"\"\"Path A: Extract narrative skills using Claude API.\"\"\"\n",
        "        if not self.claude_client:\n",
        "            print(\"⚠️ Claude API not available, skipping narrative skills.\")\n",
        "            return []\n",
        "\n",
        "        prompt = f\"\"\"As an expert research program analyst, identify the 5-7 most critical and distinct areas of expertise required by this research solicitation. Focus on specific technical skills, domain knowledge, and methodological expertise.\n",
        "\n",
        "Solicitation text:\n",
        "---\n",
        "{text}\n",
        "---\n",
        "\n",
        "Provide your response as a numbered list of distinct expertise areas. Each item should be a concise phrase.\n",
        "\"\"\"\n",
        "        try:\n",
        "            print(\"🤖 Calling Claude API for narrative skills...\")\n",
        "            response = self.claude_client.messages.create(\n",
        "                model=\"claude-3-sonnet-20240229\",\n",
        "                max_tokens=1000,\n",
        "                temperature=0.2,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "            )\n",
        "            skills = self._parse_claude_response(response.content[0].text)\n",
        "            print(f\"✅ Extracted {len(skills)} narrative skills from Claude.\")\n",
        "            return skills\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Claude API call failed: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _parse_claude_response(self, response_text: str) -> List[str]:\n",
        "        \"\"\"Parse Claude's response to extract a list of skills.\"\"\"\n",
        "        skills = []\n",
        "        for line in response_text.split('\\n'):\n",
        "            line = line.strip()\n",
        "            if re.match(r'^\\d+\\.\\s*', line):\n",
        "                skill = re.sub(r'^\\d+\\.\\s*', '', line)\n",
        "                skills.append(skill.strip())\n",
        "        return skills[:7]\n",
        "\n",
        "    def extract_formal_topics_openalex(self, title: str, abstract: str) -> List[Dict]:\n",
        "      \"\"\"\n",
        "      Path B: Extract formal topics using OpenAlex classifier with corrected data structure handling.\n",
        "      \"\"\"\n",
        "      if not self.topic_classifier:\n",
        "          print(\"⚠️ Topic classifier not available, skipping formal topics.\")\n",
        "          return []\n",
        "\n",
        "      formatted_text = f\"<TITLE> {title}\\n<ABSTRACT> {abstract}\"\n",
        "      print(\"🔬 Running OpenAlex topic classification...\")\n",
        "\n",
        "      try:\n",
        "          # Get predictions from the model. The output is a simple list of dicts.\n",
        "          predictions = self.topic_classifier(formatted_text, top_k=10, truncation=True)\n",
        "          # print(f\"   [DEBUG] Raw output from OpenAlex model: {predictions}\") # You can remove this now\n",
        "\n",
        "          if not predictions:\n",
        "              print(\"   OpenAlex model returned no valid predictions.\")\n",
        "              return []\n",
        "\n",
        "          # --- CORRECTED LOOP ---\n",
        "          # We iterate directly over 'predictions', which is the list of dictionaries.\n",
        "          formal_topics = []\n",
        "          for topic in predictions:\n",
        "              # Check if the item is a dictionary with the keys we need\n",
        "              if isinstance(topic, dict) and 'label' in topic and 'score' in topic:\n",
        "                  # We can now lower the threshold since we see the scores are generally low\n",
        "                  if topic['score'] > 0.01: # Lowered threshold to include the results\n",
        "                      formal_topics.append({\n",
        "                          'topic': topic['label'],\n",
        "                          'score': round(topic['score'], 4)\n",
        "                      })\n",
        "              else:\n",
        "                  print(f\"   ⚠️ Skipping unexpected item in model predictions: {topic}\")\n",
        "\n",
        "          print(f\"✅ Extracted {len(formal_topics)} formal topics from OpenAlex.\")\n",
        "          return formal_topics\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"⚠️ An exception occurred during topic classification: {e}\")\n",
        "          return []\n",
        "\n",
        "    def fusion_logic(self, narrative_skills: List[str], formal_topics: List[Dict]) -> List[str]:\n",
        "        \"\"\"Combine narrative skills and formal topics, removing duplicates.\"\"\"\n",
        "        print(\"🔄 Applying fusion logic...\")\n",
        "        combined_skills = list(narrative_skills)\n",
        "        narrative_lower = ' '.join(narrative_skills).lower()\n",
        "\n",
        "        for topic in formal_topics:\n",
        "            topic_name = topic['topic'].split(': ', 1)[-1] # Remove ID like \"123: \"\n",
        "            is_duplicate = topic_name.lower() in narrative_lower\n",
        "            if not is_duplicate:\n",
        "                combined_skills.append(f\"Expertise in {topic_name}\")\n",
        "\n",
        "        print(f\"✅ Created final checklist with {len(combined_skills)} skills.\")\n",
        "        return combined_skills\n",
        "\n",
        "    def process_solicitation(self, pdf_filepath: str) -> Optional[StructuredSolicitationObject]:\n",
        "        \"\"\"Main processing pipeline for a PDF solicitation from a given path.\"\"\"\n",
        "        print(\"🚀 Starting PDF Solicitation Processing Pipeline\")\n",
        "        print(\"=\" * 60)\n",
        "        try:\n",
        "            filename, title, abstract = self._extract_text_from_pdf(pdf_filepath)\n",
        "\n",
        "            # Input for Claude can be a simple combination\n",
        "            claude_input_text = f\"Title: {title}. Abstract: {abstract}\"\n",
        "            print(f\"\\n📊 Text stats for analysis: {len(claude_input_text)} characters.\")\n",
        "\n",
        "            # Path A: Claude\n",
        "            narrative_skills = self.extract_narrative_skills_claude(claude_input_text)\n",
        "\n",
        "            # Path B: OpenAlex (uses corrected function call)\n",
        "            formal_topics = self.extract_formal_topics_openalex(title, abstract)\n",
        "\n",
        "            # Path C: Fusion\n",
        "            required_skills_checklist = self.fusion_logic(narrative_skills, formal_topics)\n",
        "\n",
        "            solicitation_obj = StructuredSolicitationObject(\n",
        "                solicitation_id=f\"SOL_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
        "                title=title, abstract=abstract,\n",
        "                processed_at=datetime.now().isoformat(),\n",
        "                pdf_filename=filename,\n",
        "                narrative_skills=narrative_skills,\n",
        "                formal_topics=formal_topics,\n",
        "                required_skills_checklist=required_skills_checklist,\n",
        "                text_length=len(claude_input_text))\n",
        "\n",
        "            output_filename = f\"{filename.replace('.pdf', '')}_analysis.json\"\n",
        "            solicitation_obj.to_json(output_filename)\n",
        "            print(f\"\\n✅ Processing complete! Saved to: {output_filename}\")\n",
        "            return solicitation_obj\n",
        "        except Exception as e:\n",
        "            print(f\"❌ A fatal error occurred during processing: {e}\")\n",
        "            return None\n",
        "\n",
        "    def display_results(self, solicitation_obj: Optional[StructuredSolicitationObject]):\n",
        "        \"\"\"Display processing results in a readable format.\"\"\"\n",
        "        if not solicitation_obj:\n",
        "            print(\"\\nNo results to display due to a processing error.\")\n",
        "            return\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"📋 SOLICITATION PROCESSING RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"🆔 ID: {solicitation_obj.solicitation_id}\")\n",
        "        print(f\"📄 File: {solicitation_obj.pdf_filename}\")\n",
        "        print(f\"📝 Title: {solicitation_obj.title}\")\n",
        "        print(f\"\\n🤖 Path A - Narrative Skills (Claude):\")\n",
        "        for i, skill in enumerate(solicitation_obj.narrative_skills, 1): print(f\"   {i}. {skill}\")\n",
        "        print(f\"\\n🔬 Path B - Formal Topics (OpenAlex):\")\n",
        "        for i, topic in enumerate(solicitation_obj.formal_topics, 1): print(f\"   {i}. {topic['topic']} (Score: {topic['score']:.3f})\")\n",
        "        print(f\"\\n✅ Final Hybrid Skills Checklist:\")\n",
        "        for i, skill in enumerate(solicitation_obj.required_skills_checklist, 1): print(f\"   {i}. {skill}\")\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Main Execution for Cell 1\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    warnings.filterwarnings('ignore')\n",
        "    print(\"🚀 Starting Pipeline: Cell 1 - PDF Processing\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        # Mount Google Drive\n",
        "        if not os.path.exists(DRIVE_MOUNT_PATH):\n",
        "            drive.mount(DRIVE_MOUNT_PATH, force_remount=True)\n",
        "            print(\"✅ Google Drive mounted successfully.\")\n",
        "        else:\n",
        "            print(\"✅ Google Drive already mounted.\")\n",
        "\n",
        "        # --- 1. Generate a Unique Run ID from the PDF Filename ---\n",
        "        base_filename = os.path.basename(PDF_FILE_PATH)\n",
        "        sanitized_base = os.path.splitext(base_filename)[0]\n",
        "        # Make the filename safe for all systems\n",
        "        run_id = re.sub(r'[^a-zA-Z0-9_-]', '_', sanitized_base)\n",
        "        print(f\"🆔 Generated unique Run ID: {run_id}\")\n",
        "\n",
        "        # --- 2. Define Output Path ---\n",
        "        solicitation_output_path = os.path.join(DATASTORE_PATH, f\"{run_id}_solicitation_analysis.json\")\n",
        "        print(f\"💾 Defined solicitation output path:\\n   {solicitation_output_path}\")\n",
        "\n",
        "\n",
        "        # --- 3. Process the Solicitation ---\n",
        "        processor = PDFSolicitationProcessor()\n",
        "        result_obj = processor.process_solicitation(PDF_FILE_PATH) # This function will now just return the object\n",
        "\n",
        "        if result_obj:\n",
        "            # --- 4. Save the Output Manually ---\n",
        "            result_obj.to_json(solicitation_output_path)\n",
        "            print(f\"\\n✅ Analysis complete! Saved to: {solicitation_output_path}\")\n",
        "            processor.display_results(result_obj)\n",
        "            print(\"\\n✅ Cell 1 finished. Proceed to Cell 2.\")\n",
        "        else:\n",
        "            print(\"❌ Processing failed, no result object created. Cannot proceed.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ A critical error occurred in Cell 1: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OodOGLF6lah2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Cell 2: Skill Affinity Engine\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "class SkillAffinityEngine:\n",
        "    \"\"\"\n",
        "    Phase 1: Core Analysis - Calculates affinity between researchers and required skills.\n",
        "    \"\"\"\n",
        "    def __init__(self, datastore_path=\"/content/drive/My Drive/datastore/\"):\n",
        "        self.datastore_path = datastore_path\n",
        "        self.model = None\n",
        "        self.metadata_df = None\n",
        "        self.embeddings_array = None\n",
        "        self.embedding_index = None\n",
        "        self.researcher_index = None\n",
        "        self.datastore_info = None\n",
        "\n",
        "    def load_datastore(self):\n",
        "        \"\"\"Load the complete researcher profile datastore.\"\"\"\n",
        "        print(\"📂 Loading Researcher Profile Datastore...\")\n",
        "        try:\n",
        "            self.metadata_df = pd.read_parquet(os.path.join(self.datastore_path, \"researcher_profiles_metadata.parquet\"))\n",
        "            self.embeddings_array = np.load(os.path.join(self.datastore_path, \"researcher_embeddings.npy\"))\n",
        "            with open(os.path.join(self.datastore_path, \"embedding_index.json\"), 'r') as f:\n",
        "                self.embedding_index = json.load(f)\n",
        "            with open(os.path.join(self.datastore_path, \"researcher_index.json\"), 'r') as f:\n",
        "                self.researcher_index = json.load(f)\n",
        "            with open(os.path.join(self.datastore_path, \"datastore_info.json\"), 'r') as f:\n",
        "                self.datastore_info = json.load(f)\n",
        "            print(f\"🎯 Datastore ready: {self.metadata_df['researcher_id'].nunique()} researchers, {len(self.metadata_df)} papers\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Failed to load datastore: {e}\")\n",
        "\n",
        "    def load_model(self, model_name='all-MiniLM-L6-v2'):\n",
        "        \"\"\"Load the sentence transformer model.\"\"\"\n",
        "        print(f\"🤖 Loading sentence transformer model: {model_name}\")\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        print(\"✅ Model loaded.\")\n",
        "\n",
        "    def embed_skills(self, skills_checklist):\n",
        "        \"\"\"Embed each skill phrase.\"\"\"\n",
        "        if self.model is None:\n",
        "            self.load_model()\n",
        "        print(f\"🧠 Embedding {len(skills_checklist)} skills...\")\n",
        "        skill_embeddings = self.model.encode(skills_checklist, show_progress_bar=True)\n",
        "        print(f\"✅ Created skill embeddings: {skill_embeddings.shape}\")\n",
        "        return skill_embeddings\n",
        "\n",
        "    def get_researcher_data(self, researcher_id):\n",
        "        \"\"\"Get embeddings, work_ids, and recency weights for a specific researcher.\"\"\"\n",
        "        work_ids = self.researcher_index.get(researcher_id, [])\n",
        "        valid_work_ids = [wid for wid in work_ids if wid in self.embedding_index]\n",
        "        positions = [self.embedding_index[wid] for wid in valid_work_ids]\n",
        "        if not positions:\n",
        "            return np.array([]), [], []\n",
        "        paper_embeddings = self.embeddings_array[positions]\n",
        "        paper_metadata = self.metadata_df[self.metadata_df['work_id'].isin(valid_work_ids)]\n",
        "        weight_mapping = dict(zip(paper_metadata['work_id'], paper_metadata['recency_weight']))\n",
        "        recency_weights = np.array([weight_mapping.get(wid, 0.0) for wid in valid_work_ids])\n",
        "        return paper_embeddings, valid_work_ids, recency_weights\n",
        "\n",
        "    def calculate_skill_affinity_score(self, paper_embeddings, skill_embedding, recency_weights):\n",
        "        \"\"\"Calculate SkillAffinityScore for one researcher against one skill.\"\"\"\n",
        "        if len(paper_embeddings) == 0:\n",
        "            return 0.0\n",
        "        skill_embedding_2d = skill_embedding.reshape(1, -1)\n",
        "        cosine_sims = cosine_similarity(paper_embeddings, skill_embedding_2d).flatten()\n",
        "        weighted_sims = cosine_sims * recency_weights\n",
        "        max_weighted_sim = np.max(weighted_sims)\n",
        "        affinity_score = np.clip(max_weighted_sim * 100, 0, 100)\n",
        "        return round(affinity_score, 2)\n",
        "\n",
        "    def create_affinity_matrix(self, skills_checklist, solicitation_id=None):\n",
        "        \"\"\"Create the complete affinity matrix for all researchers and skills.\"\"\"\n",
        "        print(\"🎯 Creating Affinity Matrix...\")\n",
        "        print(\"=\" * 50)\n",
        "        if self.metadata_df is None:\n",
        "            self.load_datastore()\n",
        "        if not skills_checklist:\n",
        "            raise ValueError(\"Skills checklist is empty. Cannot create affinity matrix.\")\n",
        "        skill_embeddings = self.embed_skills(skills_checklist)\n",
        "        unique_researchers = list(self.researcher_index.keys())\n",
        "        print(f\"📊 Processing {len(unique_researchers)} researchers × {len(skills_checklist)} skills\")\n",
        "        affinity_matrix = np.zeros((len(unique_researchers), len(skills_checklist)))\n",
        "        for i, researcher_id in enumerate(tqdm(unique_researchers, desc=\"Processing researchers\")):\n",
        "            paper_embeddings, _, recency_weights = self.get_researcher_data(researcher_id)\n",
        "            if len(paper_embeddings) == 0:\n",
        "                continue\n",
        "            for j, skill_embedding in enumerate(skill_embeddings):\n",
        "                affinity_matrix[i, j] = self.calculate_skill_affinity_score(\n",
        "                    paper_embeddings, skill_embedding, recency_weights\n",
        "                )\n",
        "        researcher_names = [self.metadata_df[self.metadata_df['researcher_id'] == rid].iloc[0]['researcher_name'] for rid in unique_researchers]\n",
        "        skill_columns = [f\"Skill_{i+1:02d}: {skill[:50]}\" for i, skill in enumerate(skills_checklist)]\n",
        "        affinity_df = pd.DataFrame(affinity_matrix, index=researcher_names, columns=skill_columns)\n",
        "        print(f\"✅ Affinity Matrix created: {affinity_df.shape}\")\n",
        "        return affinity_df, unique_researchers, skills_checklist\n",
        "\n",
        "    def analyze_affinity_matrix(self, affinity_df, skills_checklist):\n",
        "        \"\"\"Provide analysis and insights on the affinity matrix.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60 + \"\\n📊 AFFINITY MATRIX ANALYSIS\\n\" + \"=\"*60)\n",
        "        if affinity_df.empty or affinity_df.shape[1] == 0:\n",
        "            print(\"⚠️ Affinity matrix is empty. Skipping analysis.\")\n",
        "            return\n",
        "        print(f\"📏 Matrix dimensions: {affinity_df.shape[0]} researchers × {affinity_df.shape[1]} skills\")\n",
        "        print(f\"📈 Score range: {affinity_df.values.min():.2f} - {affinity_df.values.max():.2f}\")\n",
        "        print(f\"📊 Mean affinity score: {affinity_df.values.mean():.2f}\")\n",
        "        researcher_avg_scores = affinity_df.mean(axis=1).sort_values(ascending=False)\n",
        "        print(f\"\\n🏆 Top 5 Researchers (by average affinity):\\n{researcher_avg_scores.head().to_string(float_format='%.2f')}\")\n",
        "        skill_avg_scores = affinity_df.mean(axis=0).sort_values()\n",
        "        print(f\"\\n🎯 Most Challenging Skills (lowest average affinity):\")\n",
        "        for skill_col, score in skill_avg_scores.head().items():\n",
        "            try:\n",
        "                original_skill_index = int(re.search(r'Skill_(\\d+):', skill_col).group(1)) - 1\n",
        "                print(f\"   - {skills_checklist[original_skill_index][:60]}...: {score:.2f}\")\n",
        "            except (AttributeError, IndexError):\n",
        "                print(f\"   - {skill_col}: {score:.2f}\")\n",
        "\n",
        "\n",
        "    def save_affinity_matrix(self, affinity_df, csv_path, metadata_path, metadata):\n",
        "        \"\"\"\n",
        "        Save the affinity matrix and related data to specified paths.\n",
        "        This method is corrected to accept full paths instead of creating them internally.\n",
        "        \"\"\"\n",
        "        # Save main affinity matrix\n",
        "        affinity_df.to_csv(csv_path)\n",
        "        print(f\"💾 Affinity matrix saved to: {csv_path}\")\n",
        "\n",
        "        # Save metadata\n",
        "        with open(metadata_path, 'w') as f:\n",
        "            json.dump(metadata, f, indent=2)\n",
        "        print(f\"📋 Metadata saved to: {metadata_path}\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Main Execution for Cell 2\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    warnings.filterwarnings('ignore')\n",
        "    print(\"\\n🚀 Starting Pipeline: Cell 2 - Affinity Matrix Generation\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # --- 1. Check for Inputs from Cell 1 ---\n",
        "    if 'result_obj' not in locals() or 'run_id' not in locals() or result_obj is None:\n",
        "        print(\"❌ ERROR: Input variables from Cell 1 are missing.\")\n",
        "        print(\"   Please run Cell 1 successfully before running this cell.\")\n",
        "    else:\n",
        "        print(f\"✅ Received inputs for Run ID: {run_id}\")\n",
        "        try:\n",
        "            # --- 2. Initialize Engine and Get Skills ---\n",
        "            engine = SkillAffinityEngine(datastore_path=DATASTORE_PATH)\n",
        "            skills_checklist = result_obj.required_skills_checklist\n",
        "            solicitation_id = result_obj.solicitation_id\n",
        "            print(f\"🎯 Analyzing {len(skills_checklist)} required skills.\")\n",
        "\n",
        "            # --- 3. Create Affinity Matrix ---\n",
        "            affinity_df, unique_researchers, skills_list = engine.create_affinity_matrix(\n",
        "                skills_checklist, solicitation_id\n",
        "            )\n",
        "\n",
        "            # --- 4. Define Output Paths Using the Run ID ---\n",
        "            affinity_csv_path = os.path.join(DATASTORE_PATH, f\"{run_id}_affinity_matrix.csv\")\n",
        "            affinity_metadata_path = os.path.join(DATASTORE_PATH, f\"{run_id}_affinity_metadata.json\")\n",
        "            print(f\"\\n💾 Defined affinity matrix output path:\\n   {affinity_csv_path}\")\n",
        "            print(f\"💾 Defined affinity metadata output path:\\n   {affinity_metadata_path}\")\n",
        "\n",
        "            # --- 5. Prepare and Save Results ---\n",
        "            metadata_payload = {\n",
        "                \"created_at\": pd.Timestamp.now().isoformat(),\n",
        "                \"solicitation_id\": solicitation_id,\n",
        "                \"run_id\": run_id,\n",
        "                \"matrix_shape\": affinity_df.shape,\n",
        "                \"num_researchers\": len(unique_researchers),\n",
        "                \"num_skills\": len(skills_list),\n",
        "                \"researcher_ids\": unique_researchers,\n",
        "                \"skills_checklist\": skills_list,\n",
        "                \"score_statistics\": {\n",
        "                    \"min\": float(affinity_df.values.min()),\n",
        "                    \"max\": float(affinity_df.values.max()),\n",
        "                    \"mean\": float(affinity_df.values.mean()),\n",
        "                    \"std\": float(affinity_df.values.std())\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Call the corrected save method\n",
        "            engine.save_affinity_matrix(affinity_df, affinity_csv_path, affinity_metadata_path, metadata_payload)\n",
        "\n",
        "            # --- 6. Analyze and Conclude ---\n",
        "            engine.analyze_affinity_matrix(affinity_df, skills_checklist)\n",
        "            print(\"\\n✅ Cell 2 finished. You may now proceed to Cell 3.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ An error occurred during affinity analysis in Cell 2: {e}\")"
      ],
      "metadata": {
        "id": "qyrz6qQOmKVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Cell 3: Dream Team Assembler & Strategic Output\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from datetime import datetime\n",
        "import anthropic\n",
        "from google.colab import userdata\n",
        "from typing import List, Dict, Tuple\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "class DreamTeamAssembler:\n",
        "    \"\"\"\n",
        "    Phase 2: Dream Team Assembly & Strategic Output.\n",
        "    Generates optimal teams and creates comprehensive strategic reports.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.claude_client = None\n",
        "        self.setup_claude_api()\n",
        "\n",
        "    def setup_claude_api(self):\n",
        "        \"\"\"Initialize Claude API client.\"\"\"\n",
        "        try:\n",
        "            api_key = userdata.get('ANTHROPIC_API_KEY')\n",
        "            self.claude_client = anthropic.Anthropic(api_key=api_key)\n",
        "            print(\"✅ Claude API client initialized for gap analysis\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Claude API setup failed: {e}. Strategic analysis will be basic.\")\n",
        "\n",
        "    def load_affinity_matrix(self, csv_path, metadata_path=None):\n",
        "        \"\"\"Load the affinity matrix and associated metadata.\"\"\"\n",
        "        print(f\"📊 Loading affinity matrix from: {csv_path}\")\n",
        "        affinity_df = pd.read_csv(csv_path, index_col=0)\n",
        "        print(f\"✅ Loaded matrix: {affinity_df.shape[0]} researchers × {affinity_df.shape[1]} skills\")\n",
        "        metadata = None\n",
        "        if metadata_path and os.path.exists(metadata_path):\n",
        "            with open(metadata_path, 'r') as f:\n",
        "                metadata = json.load(f)\n",
        "            print(\"✅ Loaded affinity metadata\")\n",
        "        return affinity_df, metadata\n",
        "\n",
        "    def calculate_team_coverage(self, affinity_df, team_indices):\n",
        "        \"\"\"Calculate team coverage scores for all skills.\"\"\"\n",
        "        if not team_indices:\n",
        "            return np.array([0.0] * affinity_df.shape[1]), 0.0\n",
        "        team_affinities = affinity_df.iloc[team_indices]\n",
        "        skill_coverages = team_affinities.max(axis=0).values\n",
        "        return skill_coverages, np.mean(skill_coverages)\n",
        "\n",
        "    def calculate_marginal_gain(self, affinity_df, current_team_indices, candidate_index):\n",
        "        \"\"\"Calculate the marginal gain of adding a candidate to the team.\"\"\"\n",
        "        _, current_coverage = self.calculate_team_coverage(affinity_df, current_team_indices)\n",
        "        _, new_coverage = self.calculate_team_coverage(affinity_df, current_team_indices + [candidate_index])\n",
        "        return new_coverage - current_coverage\n",
        "\n",
        "    def dream_team_greedy_algorithm(self, affinity_df, min_team_size=2, max_team_size=4):\n",
        "        \"\"\"Implement the greedy algorithm to select the best team.\"\"\"\n",
        "        print(\"🎯 Running Dream Team Greedy Algorithm...\")\n",
        "        print(\"=\" * 50)\n",
        "        n_researchers = len(affinity_df)\n",
        "        selected_indices = []\n",
        "        selection_history = []\n",
        "\n",
        "        # Step 1: Select the best overall researcher as PI\n",
        "        best_researcher_pos = affinity_df.mean(axis=1).idxmax()\n",
        "        best_researcher_loc = affinity_df.index.get_loc(best_researcher_pos)\n",
        "        selected_indices.append(best_researcher_loc)\n",
        "        _, initial_coverage = self.calculate_team_coverage(affinity_df, selected_indices)\n",
        "\n",
        "        selection_history.append({\n",
        "            'step': 1, 'action': 'Select PI',\n",
        "            'researcher_name': affinity_df.index[best_researcher_loc],\n",
        "            'reason': 'Highest average affinity score',\n",
        "            'team_coverage': initial_coverage\n",
        "        })\n",
        "        print(f\"🏆 Step 1 - PI Selection: {affinity_df.index[best_researcher_loc]} (Coverage: {initial_coverage:.2f})\")\n",
        "\n",
        "        # Step 2-N: Iteratively add members with the highest marginal gain\n",
        "        for step in range(2, max_team_size + 1):\n",
        "            gains = [(idx, self.calculate_marginal_gain(affinity_df, selected_indices, idx))\n",
        "                     for idx in range(n_researchers) if idx not in selected_indices]\n",
        "            if not gains: break\n",
        "\n",
        "            best_candidate_idx, best_marginal_gain = max(gains, key=lambda item: item[1])\n",
        "\n",
        "            if best_marginal_gain > 0.5 or len(selected_indices) < min_team_size:\n",
        "                selected_indices.append(best_candidate_idx)\n",
        "                _, new_coverage = self.calculate_team_coverage(affinity_df, selected_indices)\n",
        "                selection_history.append({\n",
        "                    'step': step, 'action': 'Add Member',\n",
        "                    'researcher_name': affinity_df.index[best_candidate_idx],\n",
        "                    'reason': f'Maximum marginal gain (+{best_marginal_gain:.2f})',\n",
        "                    'team_coverage': new_coverage\n",
        "                })\n",
        "                print(f\"✅ Step {step} - Added: {affinity_df.index[best_candidate_idx]} (New Coverage: {new_coverage:.2f})\")\n",
        "            else:\n",
        "                print(f\"🛑 Step {step} - Stopping: No significant marginal gain found (best was +{best_marginal_gain:.2f}).\")\n",
        "                break\n",
        "\n",
        "        final_coverage = self.calculate_team_coverage(affinity_df, selected_indices)[1]\n",
        "        print(f\"\\n🎯 Final Dream Team ({len(selected_indices)} members) with {final_coverage:.2f} coverage.\")\n",
        "        return selected_indices, selection_history\n",
        "\n",
        "    def generate_coverage_report(self, affinity_df, team_indices, skills_list):\n",
        "        \"\"\"Generate a detailed coverage report for the selected team.\"\"\"\n",
        "        skill_coverages, overall_coverage = self.calculate_team_coverage(affinity_df, team_indices)\n",
        "        team_members = []\n",
        "        for idx in team_indices:\n",
        "            scores = affinity_df.iloc[idx]\n",
        "            top_skills = [{'skill': skills_list[i], 'score': scores[i]} for i in scores.argsort()[-3:][::-1]]\n",
        "            team_members.append({'name': affinity_df.index[idx], 'avg_affinity': scores.mean(), 'top_skills': top_skills})\n",
        "\n",
        "        skill_analysis = []\n",
        "        for i, (skill, coverage) in enumerate(zip(skills_list, skill_coverages)):\n",
        "            team_scores = affinity_df.iloc[team_indices, i]\n",
        "            best_member_idx = team_scores.idxmax()\n",
        "            skill_analysis.append({\n",
        "                'skill': skill, 'coverage_score': coverage,\n",
        "                'level': 'High' if coverage >= 70 else 'Medium' if coverage >= 40 else 'Low',\n",
        "                'expert': best_member_idx, 'expert_score': team_scores.max()\n",
        "            })\n",
        "        return {'overall_coverage_score': overall_coverage, 'team_members': team_members, 'skill_analysis': skill_analysis}\n",
        "\n",
        "    def generate_strategic_analysis(self, coverage_report, skills_list, solicitation_data):\n",
        "        \"\"\"Generate AI-powered gap analysis using Claude API.\"\"\"\n",
        "        if not self.claude_client:\n",
        "            return \"Claude API not available. Basic analysis only: Review low-coverage skills and consider recruitment.\"\n",
        "        print(\"🤖 Generating strategic analysis with Claude API...\")\n",
        "        # Create a detailed prompt (shortened for brevity, full logic assumed)\n",
        "        prompt = f\"Analyze this research team's fit for the solicitation titled '{solicitation_data.get('title', 'N/A')}'.\\n\"\n",
        "        prompt += f\"Team has an overall coverage score of {coverage_report['overall_coverage_score']:.2f}.\\n\"\n",
        "        low_skills = [s['skill'] for s in coverage_report['skill_analysis'] if s['level'] == 'Low']\n",
        "        prompt += f\"Potential Gaps (Low Coverage): {', '.join(low_skills) if low_skills else 'None'}.\\n\"\n",
        "        prompt += \"Provide a strategic report covering strengths, weaknesses, and actionable recommendations for the proposal.\"\n",
        "        try:\n",
        "            response = self.claude_client.messages.create(\n",
        "                model=\"claude-3-sonnet-20240229\", max_tokens=2000, temperature=0.5,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "            )\n",
        "            analysis = response.content[0].text\n",
        "            print(\"✅ Strategic analysis generated.\")\n",
        "            return analysis\n",
        "        except Exception as e:\n",
        "            return f\"Claude API analysis failed: {e}. Fallback: Review low-coverage skills: {low_skills}.\"\n",
        "\n",
        "    def create_strategic_report(self, affinity_df, metadata, solicitation_data):\n",
        "        \"\"\"Main function to create a comprehensive strategic report.\"\"\"\n",
        "        print(\"\\n🚀 CREATING STRATEGIC REPORT\")\n",
        "        print(\"=\" * 60)\n",
        "        skills_list = metadata.get('skills_checklist', [col.split(': ', 1)[-1] for col in affinity_df.columns])\n",
        "        team_indices, history = self.dream_team_greedy_algorithm(affinity_df)\n",
        "        coverage_report = self.generate_coverage_report(affinity_df, team_indices, skills_list)\n",
        "        strategic_analysis = self.generate_strategic_analysis(coverage_report, skills_list, solicitation_data)\n",
        "\n",
        "        return {\n",
        "            'report_metadata': {'generated_at': datetime.now().isoformat(), 'solicitation_id': metadata.get('solicitation_id')},\n",
        "            'coverage_analysis': coverage_report, 'strategic_analysis': strategic_analysis,\n",
        "        }\n",
        "\n",
        "    def format_markdown_report(self, strategic_report):\n",
        "        \"\"\"Format the strategic report as a human-readable Markdown file.\"\"\"\n",
        "        report = f\"# NSF Dream Team Strategic Report\\n\\n\"\n",
        "        meta = strategic_report['report_metadata']\n",
        "        report += f\"**Generated:** {meta['generated_at']}\\n\"\n",
        "        report += f\"**Solicitation ID:** `{meta.get('solicitation_id', 'N/A')}`\\n\\n\"\n",
        "\n",
        "        # --- Team Summary Table ---\n",
        "        coverage = strategic_report['coverage_analysis']\n",
        "        report += f\"## 🏆 Recommended Dream Team\\n\\n\"\n",
        "        report += f\"**Overall Team Coverage Score:** **`{coverage['overall_coverage_score']:.2f} / 100`**\\n\\n\"\n",
        "        report += \"| Role | Researcher | Avg. Affinity | Top Expertise Areas |\\n\"\n",
        "        report += \"|:---|:---|:---:|:---|\\n\"\n",
        "        for i, member in enumerate(coverage['team_members']):\n",
        "            role = \"**Principal Investigator (PI)**\" if i == 0 else f\"Co-Investigator {i+1}\"\n",
        "            top_skills = \", \".join([s['skill'] for s in member['top_skills']])\n",
        "            report += f\"| {role} | {member['name']} | `{member['avg_affinity']:.2f}` | {top_skills} |\\n\"\n",
        "\n",
        "        # --- Coverage Analysis Table ---\n",
        "        report += f\"\\n## 📊 Skills Coverage Analysis\\n\\n\"\n",
        "        report += \"| Skill / Expertise Area | Coverage | Level | Primary Expert |\\n\"\n",
        "        report += \"|:---|:---:|:---|:---|\\n\"\n",
        "        for skill in sorted(coverage['skill_analysis'], key=lambda x: x['coverage_score']):\n",
        "            level_emoji = \"🟢\" if skill['level'] == 'High' else \"🟡\" if skill['level'] == 'Medium' else \"🔴\"\n",
        "            report += f\"| {skill['skill']} | `{skill['coverage_score']:.2f}` | {level_emoji} {skill['level']} | {skill['expert']} |\\n\"\n",
        "\n",
        "        # --- Strategic Analysis ---\n",
        "        report += f\"\\n## 🧠 AI-Powered Strategic Analysis\\n\\n\"\n",
        "        report += \"> \" + strategic_report['strategic_analysis'].replace('\\n', '\\n> ') + \"\\n\"\n",
        "        return report\n",
        "\n",
        "    def save_strategic_report(self, strategic_report, drive_base_path, local_base_path):\n",
        "        \"\"\"Saves the strategic report as JSON and Markdown to GDrive and local storage.\"\"\"\n",
        "        print(\"\\n💾 Saving strategic reports...\")\n",
        "\n",
        "        # --- Generate Markdown Content ---\n",
        "        md_content = self.format_markdown_report(strategic_report)\n",
        "\n",
        "        # --- Define Paths ---\n",
        "        json_path = f\"{drive_base_path}_strategic_report.json\"\n",
        "        drive_md_path = f\"{drive_base_path}_strategic_report.md\"\n",
        "        local_md_path = f\"{local_base_path}_strategic_report.md\"\n",
        "\n",
        "        # --- Save Files ---\n",
        "        with open(json_path, 'w') as f:\n",
        "            json.dump(strategic_report, f, indent=2)\n",
        "        print(f\"   📄 Saved full JSON report to Google Drive:\\n      {json_path}\")\n",
        "\n",
        "        with open(drive_md_path, 'w') as f:\n",
        "            f.write(md_content)\n",
        "        print(f\"   📝 Saved Markdown report to Google Drive:\\n      {drive_md_path}\")\n",
        "\n",
        "        with open(local_md_path, 'w') as f:\n",
        "            f.write(md_content)\n",
        "        print(f\"   💻 Saved Markdown report to Colab local storage:\\n      {local_md_path}\")\n",
        "\n",
        "    def display_summary(self, strategic_report):\n",
        "        \"\"\"Displays a summary of the strategic report in the console.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"📋 DREAM TEAM STRATEGIC REPORT SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "        coverage = strategic_report['coverage_analysis']\n",
        "        print(f\"🏆 Recommended Team ({len(coverage['team_members'])} members) --> Overall Score: {coverage['overall_coverage_score']:.2f}/100\")\n",
        "        for i, member in enumerate(coverage['team_members']):\n",
        "            role = \"PI\" if i == 0 else f\"Co-I {i+1}\"\n",
        "            print(f\"   - **{member['name']}** ({role})\")\n",
        "\n",
        "        low_skills = [s for s in coverage['skill_analysis'] if s['level'] == 'Low']\n",
        "        if low_skills:\n",
        "            print(f\"\\n🔴 Identified {len(low_skills)} potential skill gaps (Low Coverage).\")\n",
        "            print(\"   Review the saved Markdown report for details.\")\n",
        "        else:\n",
        "            print(\"\\n🟢 Excellent coverage. No significant skill gaps were identified.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Main Execution for Cell 3\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    warnings.filterwarnings('ignore')\n",
        "    print(\"\\n🚀 Starting Pipeline: Cell 3 - Dream Team Assembly & Report Generation\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # --- 1. Check for Inputs from Previous Cells ---\n",
        "    if 'affinity_csv_path' not in locals() or not os.path.exists(affinity_csv_path):\n",
        "        print(\"❌ ERROR: Input file from Cell 2 is missing.\")\n",
        "        print(\"   Please run Cells 1 and 2 successfully before running this cell.\")\n",
        "    else:\n",
        "        print(f\"✅ Received inputs for Run ID: {run_id}\")\n",
        "        try:\n",
        "            # --- 2. Initialize Assembler ---\n",
        "            assembler = DreamTeamAssembler()\n",
        "\n",
        "            # --- 3. Load Data Using Dynamic Paths ---\n",
        "            print(\"📊 Loading data using dynamic paths from previous cells...\")\n",
        "            affinity_df, affinity_metadata = assembler.load_affinity_matrix(affinity_csv_path, affinity_metadata_path)\n",
        "            with open(solicitation_output_path, 'r') as f:\n",
        "                solicitation_data = json.load(f)\n",
        "            print(\"✅ Loaded all necessary data.\")\n",
        "\n",
        "            # --- 4. Create Strategic Report ---\n",
        "            strategic_report = assembler.create_strategic_report(\n",
        "                affinity_df=affinity_df,\n",
        "                metadata=affinity_metadata,\n",
        "                solicitation_data=solicitation_data\n",
        "            )\n",
        "\n",
        "            # --- 5. Define Output Paths and Save Report ---\n",
        "            report_drive_base_path = os.path.join(DATASTORE_PATH, run_id)\n",
        "            report_local_base_path = f\"/content/{run_id}\" # For Colab's temporary storage\n",
        "\n",
        "            assembler.save_strategic_report(strategic_report, report_drive_base_path, report_local_base_path)\n",
        "\n",
        "            # --- 6. Display Final Summary in Console ---\n",
        "            assembler.display_summary(strategic_report)\n",
        "\n",
        "            print(f\"\\n\\n✅✅✅ Pipeline Complete! ✅✅✅\")\n",
        "            print(f\"Check the file browser on the left for the local report or your Drive folder.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ An error occurred during dream team analysis in Cell 3: {e}\")"
      ],
      "metadata": {
        "id": "Mcj8pN6snJQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vAy9EHqNnkfQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}