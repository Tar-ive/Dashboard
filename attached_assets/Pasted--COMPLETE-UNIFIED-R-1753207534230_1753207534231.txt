# ==============================================================================# COMPLETE UNIFIED RESEARCHER MATCHING & DREAM TEAM SYSTEM# ==============================================================================import jsonimport numpy as npimport pandas as pdimport pickleimport loggingfrom pathlib import Pathfrom typing import Dict, List, Tuple, Optional, Anyfrom dataclasses import dataclass, asdictfrom sklearn.metrics.pairwise import cosine_similarityfrom sentence_transformers import SentenceTransformerimport timeimport warningsfrom datetime import datetimeimport os# Try to import Groq API (optional)try:

from groq import Groq

GROQ_AVAILABLE = Trueexcept ImportError:

GROQ_AVAILABLE = False

print("‚ö†Ô∏è Groq library not installed. GAP analysis will be basic.")

print(" Install with: pip install groq")# Try to import Google Colab userdata (optional)try:

from google.colab import userdata

COLAB_AVAILABLE = Trueexcept ImportError:

COLAB_AVAILABLE = False



warnings.filterwarnings('ignore')# ==============================================================================# CONFIGURATION - CHANGE THESE PATHS# ==============================================================================

solicitation_file = "/content/drive/MyDrive/datastore/NSF 23-506_ Expanding AI Innovation through Capacity Building and Partnerships (ExpandAI) _ NSF - National Science Foundation_enhanced_analysis.json"

researcher_data_dir = "/content/drive/MyDrive/datastore/v2_DATA"

output_dir = "/content/drive/MyDrive/datastore"# ==============================================================================# GROQ API SETUP (OPTIONAL - FOR AI-POWERED STRATEGIC ANALYSIS)# ==============================================================================# 1. Get free API key at: https://console.groq.com/# 2. In Google Colab: Go to left sidebar > Secrets > Add new secret# Name: GROQ_API_KEY, Value: your_api_key_here# 3. Or set environment variable: export GROQ_API_KEY=your_api_key_here# ==============================================================================# ==============================================================================# CORE CLASSES# ==============================================================================@dataclassclass ResearcherMatch:

researcher_id: str

researcher_name: str

academic_expertise_score: float

s_sparse: float

s_dense: float

f_ge: float

final_affinity_score: float

total_papers: int

eligibility_status: str@dataclassclass MatchingResults:

solicitation_title: str

eligible_researchers: int

total_researchers: int

top_matches: List[ResearcherMatch]

skills_analyzed: List[str]

processing_time_seconds: float@dataclassclass DreamTeamReport:

team_members: List[Dict]

overall_coverage_score: float

skill_analysis: List[Dict]

strategic_analysis: str

selection_history: List[Dict]

generated_at: strclass UnifiedResearcherSystem:

"""

Complete system that combines researcher matching with dream team assembly

and strategic GAP analysis using Claude API.

"""



def __init__(self, data_dir: str):

self.data_dir = Path(data_dir)

self.alpha = 0.7 # TF-IDF weight

self.beta = 0.3 # Dense weight

self.groq_client = None

self.setup_groq_api()

self.load_data()



def setup_groq_api(self):

"""Initialize Groq API client if available."""

if not GROQ_AVAILABLE:

print("‚ö†Ô∏è Groq API not available. Strategic analysis will be basic.")

print(" Install with: pip install groq")

return



try:

if COLAB_AVAILABLE:

api_key = userdata.get('GROQ_API_KEY')

else:

api_key = os.environ.get('GROQ_API_KEY')



if api_key:

self.groq_client = Groq(api_key=api_key)

print("‚úÖ Groq API client initialized for strategic analysis")

else:

print("‚ö†Ô∏è Groq API key not found. Set GROQ_API_KEY.")

print(" Get free API key at: https://console.groq.com/")

except Exception as e:

print(f"‚ö†Ô∏è Groq API setup failed: {e}. Strategic analysis will be basic.")



def load_data(self):

"""Load all preprocessed researcher data."""

print("üìÇ Loading preprocessed data...")



# Handle pickle loading issue - define dummy class if needed

try:

# Try to load TF-IDF model normally first

with open(self.data_dir / 'tfidf_model.pkl', 'rb') as f:

self.tfidf_model = pickle.load(f)

except AttributeError as e:

if "ResearcherProfileProcessor" in str(e):

print("üîß Fixing pickle compatibility issue...")

# Create a dummy class to handle the pickle loading

import sys

class ResearcherProfileProcessor:

def comma_tokenizer(self, text: str):

return [token.strip() for token in text.split(',') if token.strip()]



# Add the class to the current module

sys.modules[__name__].ResearcherProfileProcessor = ResearcherProfileProcessor



# Try loading again

with open(self.data_dir / 'tfidf_model.pkl', 'rb') as f:

self.tfidf_model = pickle.load(f)

print("‚úÖ TF-IDF model loaded successfully")

else:

raise e



# Load researcher vectors

researcher_data = np.load(self.data_dir / 'researcher_vectors.npz', allow_pickle=True)

vectors = researcher_data['vectors']

researcher_ids = researcher_data['researcher_ids']

self.researcher_vectors = dict(zip(researcher_ids, vectors))



# Load paper embeddings

conceptual_data = np.load(self.data_dir / 'conceptual_profiles.npz', allow_pickle=True)

embeddings = conceptual_data['embeddings']

work_ids = conceptual_data['work_ids']

self.conceptual_profiles = dict(zip(work_ids, embeddings))



# Load evidence index

with open(self.data_dir / 'evidence_index.json', 'r') as f:

self.evidence_index = json.load(f)



# Load metadata

self.researcher_metadata = pd.read_parquet(self.data_dir / 'researcher_metadata.parquet')



# Load sentence model

self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')



print(f"‚úÖ Loaded {len(self.researcher_vectors)} researchers")

self.diagnose_data_quality()



def diagnose_data_quality(self):

"""Diagnose potential data quality issues."""

print("\nüîç DIAGNOSING DATA QUALITY")

print("-" * 40)



# Check TF-IDF model

try:

vocab_size = len(self.tfidf_model.get_feature_names_out())

print(f"TF-IDF vocabulary size: {vocab_size}")



vocab = list(self.tfidf_model.get_feature_names_out())

print(f"First 20 TF-IDF features: {vocab[:20]}")

print(f"Last 20 TF-IDF features: {vocab[-20:]}")



except Exception as e:

print(f"‚ùå Error accessing TF-IDF vocabulary: {e}")



# Check researcher vectors

print(f"Researcher vectors: {len(self.researcher_vectors)}")

if self.researcher_vectors:

sample_vector = next(iter(self.researcher_vectors.values()))

print(f"Vector dimensions: {sample_vector.shape}")

print(f"Sample vector sum: {sample_vector.sum():.4f}")



# Check conceptual profiles

print(f"Conceptual profiles: {len(self.conceptual_profiles)}")

if self.conceptual_profiles:

sample_embedding = next(iter(self.conceptual_profiles.values()))

print(f"Embedding dimensions: {sample_embedding.shape}")



# Check evidence index

print(f"Evidence index researchers: {len(self.evidence_index)}")



# Check overlap between evidence index and conceptual profiles

all_evidence_papers = set()

for researcher_papers in self.evidence_index.values():

for topic_papers in researcher_papers.values():

all_evidence_papers.update(topic_papers)



conceptual_papers = set(self.conceptual_profiles.keys())

overlap = all_evidence_papers.intersection(conceptual_papers)



print(f"Papers in evidence index: {len(all_evidence_papers)}")

print(f"Papers with embeddings: {len(conceptual_papers)}")

print(f"Overlap: {len(overlap)}")



if len(overlap) == 0:

print("‚ùå CRITICAL: No overlap between evidence index and conceptual profiles!")

elif len(overlap) < len(all_evidence_papers) * 0.5:

print("‚ö†Ô∏è WARNING: Low overlap between evidence index and conceptual profiles!")



print("-" * 40)



def filter_eligibility(self, solicitation_obj, researchers):

"""Simple eligibility filtering."""

eligible = set(researchers)

eligibility = getattr(solicitation_obj, 'eligibility', {})



# Early-career filter

if eligibility and any('early' in str(v).lower() for v in eligibility.values() if v):

early_career = self.researcher_metadata[

self.researcher_metadata['first_publication_year'] >= 2015

]['researcher_openalex_id'].tolist()

eligible = eligible.intersection(set(early_career))

print(f" Applied early-career filter: {len(eligible)} remain")



# Grant experience filter

if eligibility and any('grant' in str(v).lower() or 'funding' in str(v).lower() for v in eligibility.values() if v):

experienced = self.researcher_metadata[

self.researcher_metadata['grant_experience_factor'] > 0

]['researcher_openalex_id'].tolist()

eligible = eligible.intersection(set(experienced))

print(f" Applied grant experience filter: {len(eligible)} remain")



return list(eligible)



def extract_keywords_from_skills(self, skills: List[str]) -> List[str]:

"""Extract keywords from solicitation skills using same logic as researcher topics."""

import re



stop_words = {'and', 'in', 'of', 'for', 'the', 'a', 'an', 'to', 'with', 'on', 'at', 'by',

'expertise', 'experience', 'knowledge', 'ability', 'skills', 'understanding',

'capacity', 'proficiency', 'e.g.', 'eg', 'including', 'such', 'as'}



all_keywords = []



for skill in skills:

# Clean and split

cleaned = re.sub(r'[^\w\s-]', ' ', skill.lower())

words = cleaned.split()



# Extract meaningful keywords

for word in words:

word = word.strip('-')

if (len(word) >= 3 and

word not in stop_words and

not word.isdigit()):

all_keywords.append(word)



return all_keywords



def score_researcher(self, researcher_id, skills, solicitation_embedding, debug_mode=False):

"""Score a single researcher with optional debug output."""

try:

# Get metadata

researcher_row = self.researcher_metadata[

self.researcher_metadata['researcher_openalex_id'] == researcher_id

]

if researcher_row.empty:

return None



researcher_name = researcher_row.iloc[0]['researcher_name']

total_papers = int(researcher_row.iloc[0]['total_papers'])

grant_factor = researcher_row.iloc[0]['grant_experience_factor']



# Extract keywords and format with commas (same as researcher documents)

solicitation_keywords = self.extract_keywords_from_skills(skills)

solicitation_text = ', '.join(solicitation_keywords)



if debug_mode:

print(f"DEBUG - Researcher: {researcher_name}")

print(f" Original skills count: {len(skills)}")

print(f" Extracted keywords: {solicitation_keywords[:10]}...")

print(f" Solicitation text: {solicitation_text[:100]}...")



# Calculate sparse score (TF-IDF)

if researcher_id not in self.researcher_vectors:

if debug_mode:

print(f" WARNING: No TF-IDF vector for {researcher_id}")

s_sparse = 0.0

else:

try:

solicitation_vector = self.tfidf_model.transform([solicitation_text])

researcher_vector = self.researcher_vectors[researcher_id].reshape(1, -1)



if debug_mode:

print(f" Solicitation vector shape: {solicitation_vector.shape}")

print(f" Researcher vector shape: {researcher_vector.shape}")

print(f" Solicitation vector sum: {solicitation_vector.sum()}")

print(f" Researcher vector sum: {researcher_vector.sum()}")

if hasattr(solicitation_vector, 'nnz'):

print(f" Solicitation non-zero elements: {solicitation_vector.nnz}")





if solicitation_vector.sum() == 0 or researcher_vector.sum() == 0:

if debug_mode:

print(f" WARNING: Zero vector detected")

s_sparse = 0.0

else:

similarity = cosine_similarity(solicitation_vector, researcher_vector)[0][0]

s_sparse = float(similarity * 100)

if debug_mode:

print(f" TF-IDF similarity: {similarity}")

except Exception as tfidf_error:

if debug_mode:

print(f" TF-IDF ERROR: {tfidf_error}")

s_sparse = 0.0



# Calculate dense score (max similarity across papers)

s_dense = 0.0

papers_checked = 0

papers_found = 0

if researcher_id in self.evidence_index:

# Get all papers for this researcher from evidence index

researcher_papers = []

for topic_papers in self.evidence_index[researcher_id].values():

researcher_papers.extend(topic_papers)

researcher_papers = list(set(researcher_papers)) # Remove duplicates



if debug_mode:

print(f" Papers from evidence index: {len(researcher_papers)}")



max_sim = 0.0

for paper_id in researcher_papers:

papers_checked += 1

if paper_id in self.conceptual_profiles:

papers_found += 1

paper_embedding = self.conceptual_profiles[paper_id]

try:

sim = cosine_similarity(

solicitation_embedding.reshape(1, -1),

paper_embedding.reshape(1, -1)

)[0][0]

max_sim = max(max_sim, sim)

except Exception as dense_error:

if debug_mode:

print(f" Dense similarity error for paper {paper_id}: {dense_error}")



s_dense = float(max_sim * 100)

if debug_mode:

print(f" Papers checked: {papers_checked}, Papers with embeddings: {papers_found}")

print(f" Max dense similarity: {max_sim}")

else:

if debug_mode:

print(f" No evidence index entry for researcher")



# Calculate final scores

f_ge = max(1.0, min(3.0, 1.0 + (grant_factor * 0.2)))

academic_expertise = (self.alpha * s_sparse) + (self.beta * s_dense)

final_score = academic_expertise * f_ge



if debug_mode:

print(f" Final scores - Sparse: {s_sparse:.2f}, Dense: {s_dense:.2f}, Grant: {f_ge:.2f}")

print(f" Academic: {academic_expertise:.2f}, Final: {final_score:.2f}")

print("-" * 50)



return ResearcherMatch(

researcher_id=researcher_id,

researcher_name=researcher_name,

academic_expertise_score=academic_expertise,

s_sparse=s_sparse,

s_dense=s_dense,

f_ge=f_ge,

final_affinity_score=final_score,

total_papers=total_papers,

eligibility_status="Eligible"

)

except Exception as e:

if debug_mode:

print(f"ERROR scoring {researcher_id}: {e}")

import traceback

traceback.print_exc()

return None



def search_researchers(self, solicitation_obj, debug_first_n=3):

"""Main search function to rank researchers."""

start_time = time.time()



print(f"\nüîç ANALYZING: {solicitation_obj.title[:80]}...")



# Get skills

skills = solicitation_obj.required_skills_checklist

print(f"üìä Skills to analyze: {len(skills)}")



# Create solicitation embedding

solicitation_text = f"{solicitation_obj.title}. {solicitation_obj.abstract}"

solicitation_embedding = self.sentence_model.encode(solicitation_text)



# Get all researchers

all_researchers = list(self.researcher_metadata['researcher_openalex_id'])

print(f"üë• Total researchers: {len(all_researchers)}")



# Filter by eligibility

eligible = self.filter_eligibility(solicitation_obj, all_researchers)

print(f"‚úÖ Eligible researchers: {len(eligible)}")



# Score all eligible researchers

print("üîÑ Calculating scores...")

matches = []

debug_count = 0



for researcher_id in eligible:

# Debug first N researchers to avoid spam

debug_mode = debug_count < debug_first_n

if debug_mode:

debug_count += 1



result = self.score_researcher(researcher_id, skills, solicitation_embedding, debug_mode)



if result:

matches.append(result)



# Sort by score

matches.sort(key=lambda x: x.final_affinity_score, reverse=True)



processing_time = time.time() - start_time



return MatchingResults(

solicitation_title=solicitation_obj.title,

eligible_researchers=len(eligible),

total_researchers=len(all_researchers),

top_matches=matches,

skills_analyzed=skills,

processing_time_seconds=round(processing_time, 2)

)



def create_affinity_matrix(self, matching_results, top_n_researchers=20):

"""Create an affinity matrix from matching results."""

print(f"\nüìä Creating affinity matrix for top {top_n_researchers} researchers...")



# Get top researchers

top_matches = matching_results.top_matches[:top_n_researchers]

researcher_names = [match.researcher_name for match in top_matches]

skills = matching_results.skills_analyzed



# Create matrix: researchers √ó skills

affinity_matrix = np.zeros((len(top_matches), len(skills)))



for i, match in enumerate(top_matches):

# For each researcher, calculate their affinity to each skill

researcher_id = match.researcher_id



for j, skill in enumerate(skills):

# Calculate skill-specific affinity score

skill_keywords = self.extract_keywords_from_skills([skill])

skill_text = ', '.join(skill_keywords)



try:

# TF-IDF similarity for this specific skill

skill_vector = self.tfidf_model.transform([skill_text])

researcher_vector = self.researcher_vectors[researcher_id].reshape(1, -1)

sparse_sim = cosine_similarity(skill_vector, researcher_vector)[0][0] * 100



# Dense similarity (using overall solicitation embedding as proxy)

# In practice, you might want to create skill-specific embeddings

# For simplicity, let's use the max dense score from the overall matching

dense_sim = match.s_dense # Use the pre-calculated max dense score for the researcher





# Combined affinity score for this skill

skill_affinity = (self.alpha * sparse_sim) + (self.beta * dense_sim)

affinity_matrix[i, j] = max(0, skill_affinity) # Ensure non-negative



except Exception as e:

# Fallback: use overall academic score

affinity_matrix[i, j] = match.academic_expertise_score



# Create DataFrame

affinity_df = pd.DataFrame(

affinity_matrix,

index=researcher_names,

columns=[f"Skill_{i+1}: {skill}" for i, skill in enumerate(skills)]

)



print(f"‚úÖ Created affinity matrix: {affinity_df.shape[0]} researchers √ó {affinity_df.shape[1]} skills")

return affinity_df



def calculate_team_coverage(self, affinity_df, team_indices):

"""Calculate team coverage scores for all skills."""

if not team_indices:

return np.array([0.0] * affinity_df.shape[1]), 0.0

team_affinities = affinity_df.iloc[team_indices]

skill_coverages = team_affinities.max(axis=0).values

return skill_coverages, np.mean(skill_coverages)



def calculate_marginal_gain(self, affinity_df, current_team_indices, candidate_index):

"""Calculate the marginal gain of adding a candidate to the team."""

_, current_coverage = self.calculate_team_coverage(affinity_df, current_team_indices)

_, new_coverage = self.calculate_team_coverage(affinity_df, current_team_indices + [candidate_index])

return new_coverage - current_coverage



def dream_team_hybrid_strategy(self, affinity_df, guaranteed_top_n=2, max_team_size=4):

"""

Hybrid approach: Lock in top N performers, then optimize coverage for remaining slots.

This ensures we get researchers with proven grant experience and keyword matching.

"""

print(f"\nüéØ Running Hybrid Dream Team Strategy")

print(f" Step 1: Lock in top {guaranteed_top_n} performers")

print(f" Step 2: Optimize coverage for remaining {max_team_size - guaranteed_top_n} slots")

print("=" * 50)



# Phase 1: Lock in top performers (they earned their ranking!)

researcher_averages = affinity_df.mean(axis=1).sort_values(ascending=False)

top_performers = researcher_averages.head(guaranteed_top_n)



selected_indices = []

selection_history = []



print("üîí LOCKING IN TOP PERFORMERS:")

for i, (name, avg_score) in enumerate(top_performers.items()):

idx = affinity_df.index.get_loc(name)

selected_indices.append(idx)

role = "PI" if i == 0 else f"Co-PI {i}"



selection_history.append({

'step': i + 1,

'action': f'Lock {role}',

'researcher_name': name,

'reason': f'Top {i+1} performer (avg: {avg_score:.2f}, proven track record)',

'team_coverage': 0 # Will calculate after

})

print(f" ‚úÖ {name} ({role}) - Avg Score: {avg_score:.2f}")



# Calculate coverage after locking in top performers

_, coverage_after_top = self.calculate_team_coverage(affinity_df, selected_indices)

print(f" üìä Coverage after top {guaranteed_top_n}: {coverage_after_top:.2f}")



# Update coverage in history

for entry in selection_history:

entry['team_coverage'] = coverage_after_top



# Phase 2: Optimize remaining slots for coverage

print(f"\nüéØ OPTIMIZING REMAINING {max_team_size - guaranteed_top_n} SLOTS FOR COVERAGE:")

n_researchers = len(affinity_df)



for step in range(guaranteed_top_n + 1, max_team_size + 1):

# Calculate marginal gains for all remaining researchers

gains = [(idx, self.calculate_marginal_gain(affinity_df, selected_indices, idx))

for idx in range(n_researchers) if idx not in selected_indices]



if not gains:

print(f" ‚ö†Ô∏è No more candidates available")

break



# Sort by marginal gain and show top candidates

top_candidates = sorted(gains, key=lambda x: x[1], reverse=True)[:5]

best_candidate_idx, best_marginal_gain = top_candidates[0]



print(f" üìä Top candidates for slot {step - guaranteed_top_n}:")

for i, (idx, gain) in enumerate(top_candidates):

candidate_name = affinity_df.index[idx]

candidate_avg = affinity_df.iloc[idx].mean()

marker = "üëë" if i == 0 else f" {i+1}."

print(f" {marker} {candidate_name} (Avg: {candidate_avg:.2f}, Coverage Gain: +{gain:.2f})")



# Add the best candidate for coverage

if best_marginal_gain > 0.1: # Lower threshold since we have strong foundation

selected_indices.append(best_candidate_idx)

_, new_coverage = self.calculate_team_coverage(affinity_df, selected_indices)



selection_history.append({

'step': step,

'action': 'Add for Coverage',

'researcher_name': affinity_df.index[best_candidate_idx],

'reason': f'Best coverage gain (+{best_marginal_gain:.2f})',

'team_coverage': new_coverage

})

print(f" ‚úÖ Added: {affinity_df.index[best_candidate_idx]} (New Coverage: {new_coverage:.2f})")

else:

print(f" üõë Stopping: Marginal gain {best_marginal_gain:.2f} too small")

break



final_coverage = self.calculate_team_coverage(affinity_df, selected_indices)[1]

print(f"\nüéØ Final Hybrid Team ({len(selected_indices)} members) with {final_coverage:.2f} coverage")

print(f" Strategy: Top {guaranteed_top_n} performers + coverage optimization")



return selected_indices, selection_history



def dream_team_greedy_algorithm(self, affinity_df, min_team_size=2, max_team_size=4, marginal_threshold=0.25):

"""Implement the greedy algorithm to select the best team."""

print("\nüéØ Running Pure Greedy Algorithm...")

print("=" * 50)

n_researchers = len(affinity_df)

selected_indices = []

selection_history = []



# Step 1: Select the best overall researcher as PI

best_researcher_pos = affinity_df.mean(axis=1).idxmax()

best_researcher_loc = affinity_df.index.get_loc(best_researcher_pos)

selected_indices.append(best_researcher_loc)

_, initial_coverage = self.calculate_team_coverage(affinity_df, selected_indices)



selection_history.append({

'step': 1, 'action': 'Select PI',

'researcher_name': affinity_df.index[best_researcher_loc],

'reason': 'Highest average affinity score',

'team_coverage': initial_coverage

})

print(f"üèÜ Step 1 - PI Selection: {affinity_df.index[best_researcher_loc]} (Coverage: {initial_coverage:.2f})")



# Step 2-N: Iteratively add members with the highest marginal gain

for step in range(2, max_team_size + 1):

gains = [(idx, self.calculate_marginal_gain(affinity_df, selected_indices, idx))

for idx in range(n_researchers) if idx not in selected_indices]

if not gains:

break



best_candidate_idx, best_marginal_gain = max(gains, key=lambda item: item[1])



# Show top 3 candidates for transparency

top_candidates = sorted(gains, key=lambda x: x[1], reverse=True)[:3]

print(f" üìä Top candidates for Step {step}:")

for i, (idx, gain) in enumerate(top_candidates):

candidate_name = affinity_df.index[idx]

print(f" {i+1}. {candidate_name} (Marginal gain: +{gain:.2f})")



# More flexible stopping criteria

should_add = (

best_marginal_gain > marginal_threshold or # Significant gain

len(selected_indices) < min_team_size or # Haven't reached minimum

(step <= 4 and best_marginal_gain > 0.1) # Force at least 4 if minimal gain

)



if should_add:

selected_indices.append(best_candidate_idx)

_, new_coverage = self.calculate_team_coverage(affinity_df, selected_indices)

selection_history.append({

'step': step, 'action': 'Add Member',

'researcher_name': affinity_df.index[best_candidate_idx],

'reason': f'Maximum marginal gain (+{best_marginal_gain:.2f})',

'team_coverage': new_coverage

})

print(f"‚úÖ Step {step} - Added: {affinity_df.index[best_candidate_idx]} (New Coverage: {new_coverage:.2f})")

else:

print(f"üõë Step {step} - Stopping: Marginal gain {best_marginal_gain:.2f} below threshold {marginal_threshold}")

break



final_coverage = self.calculate_team_coverage(affinity_df, selected_indices)[1]

print(f"\nüéØ Final Dream Team ({len(selected_indices)} members) with {final_coverage:.2f} coverage.")

return selected_indices, selection_history



def generate_coverage_report(self, affinity_df, team_indices, skills_list):

"""Generate a detailed coverage report for the selected team."""

skill_coverages, overall_coverage = self.calculate_team_coverage(affinity_df, team_indices)



team_members = []

for idx in team_indices:

scores = affinity_df.iloc[idx]

top_skills = [{'skill': skills_list[i], 'score': scores[i]}

for i in scores.argsort()[-3:][::-1]]

team_members.append({

'name': affinity_df.index[idx],

'avg_affinity': scores.mean(),

'top_skills': top_skills

})



skill_analysis = []

for i, (skill, coverage) in enumerate(zip(skills_list, skill_coverages)):

team_scores = affinity_df.iloc[team_indices, i]

if not team_scores.empty: # Handle case where team is empty or skill has no coverage

best_member_name = team_scores.idxmax()

expert_score = team_scores.max()

else:

best_member_name = "N/A"

expert_score = 0.0





skill_analysis.append({

'skill': skill,

'coverage_score': coverage,

'level': 'High' if coverage >= 70 else 'Medium' if coverage >= 40 else 'Low',

'expert': best_member_name,

'expert_score': expert_score

})



return {

'overall_coverage_score': overall_coverage,

'team_members': team_members,

'skill_analysis': skill_analysis

}



def generate_strategic_analysis(self, coverage_report, skills_list, solicitation_data):

"""Generate AI-powered gap analysis using Groq API."""

if not self.groq_client:

# Basic fallback analysis

low_skills = [s['skill'] for s in coverage_report['skill_analysis'] if s['level'] == 'Low']

basic_analysis = f"""

BASIC STRATEGIC ANALYSIS (Groq API not available):



Team Coverage Score: {coverage_report['overall_coverage_score']:.2f}/100



STRENGTHS:

- Team assembled using advanced affinity matching

- {len(coverage_report['team_members'])} selected team members

- Covers {len(skills_list)} required skill areas



POTENTIAL GAPS:{f"- Low coverage areas: {', '.join(low_skills)}" if low_skills else "- No significant gaps identified"}



RECOMMENDATIONS:

- Review low-coverage skills for additional expertise

- Consider collaboration with external partners if needed

- Leverage team members' top skills for proposal strength

"""

return basic_analysis.strip()



print("ü§ñ Generating strategic analysis with Groq API...")



# Create detailed prompt for Groq

team_info = "\n".join([f"- {member['name']} (avg affinity: {member['avg_affinity']:.2f})"

for member in coverage_report['team_members']])



low_skills = [s for s in coverage_report['skill_analysis'] if s['level'] == 'Low']

medium_skills = [s for s in coverage_report['skill_analysis'] if s['level'] == 'Medium']

high_skills = [s for s in coverage_report['skill_analysis'] if s['level'] == 'High']



prompt = f"""

Analyze this research team's fit for the NSF solicitation titled: "{solicitation_data.get('title', 'N/A')}"



TEAM COMPOSITION:{team_info}



COVERAGE ANALYSIS:

- Overall team coverage score: {coverage_report['overall_coverage_score']:.2f}/100

- High coverage skills ({len(high_skills)}): {', '.join([s['skill'] for s in high_skills[:5]])}

- Medium coverage skills ({len(medium_skills)}): {', '.join([s['skill'] for s in medium_skills[:5]])}

- Low coverage skills ({len(low_skills)}): {', '.join([s['skill'] for s in low_skills])}



Please provide a strategic analysis covering:

1. Team strengths and competitive advantages

2. Critical gaps and risks

3. Specific recommendations for proposal development

4. Potential collaboration or recruitment strategies

5. Overall competitiveness assessment



Keep the analysis practical and actionable for proposal development.

"""



try:

response = self.groq_client.chat.completions.create(

model="meta-llama/llama-4-scout-17b-16e-instruct", # Free Groq model

messages=[{"role": "user", "content": prompt}],

max_tokens=2000,

temperature=0.5

)

analysis = response.choices[0].message.content

print("‚úÖ Strategic analysis generated with Groq API")

return analysis

except Exception as e:

print(f"‚ùå Groq API analysis failed: {e}")

# Fallback to basic analysis

low_skills_list = [s['skill'] for s in low_skills]

return f"Groq API failed. Basic analysis: Team coverage is {coverage_report['overall_coverage_score']:.2f}/100. Review low-coverage skills: {', '.join(low_skills_list) if low_skills_list else 'None identified'}."



def dream_team_by_rankings(self, affinity_df, team_size=4):

"""Alternative approach: Simply select top N researchers by overall ranking."""

print(f"\nüìä ALTERNATIVE: Dream Team by Rankings (Top {team_size})")

print("=" * 50)



# Sort by average affinity (overall performance)

researcher_averages = affinity_df.mean(axis=1).sort_values(ascending=False)

top_researchers = researcher_averages.head(team_size)



team_indices = [affinity_df.index.get_loc(name) for name in top_researchers.index]

_, coverage = self.calculate_team_coverage(affinity_df, team_indices)



print("Selected team (by ranking):")

for i, (name, avg_score) in enumerate(top_researchers.items()):

role = "PI" if i == 0 else f"Co-I {i}"

print(f" {i+1}. {name} ({role}) - Avg Score: {avg_score:.2f}")



print(f"Team coverage by rankings: {coverage:.2f}")

return team_indices, coverage



def compare_team_strategies(self, affinity_df, skills_list):

"""Compare different team selection strategies."""

print("\nüî¨ COMPARING TEAM SELECTION STRATEGIES")

print("=" * 60)



# Strategy 1: Hybrid approach (lock top 2 + coverage optimization) - PREFERRED

hybrid_indices, hybrid_history = self.dream_team_hybrid_strategy(affinity_df, guaranteed_top_n=2, max_team_size=4)

hybrid_coverage = self.calculate_team_coverage(affinity_df, hybrid_indices)[1]



# Strategy 2: Pure greedy algorithm (optimized coverage)

greedy_indices, greedy_history = self.dream_team_greedy_algorithm(affinity_df, marginal_threshold=0.25, max_team_size=4)

greedy_coverage = self.calculate_team_coverage(affinity_df, greedy_indices)[1]



# Strategy 3: Top performers by ranking

ranking_indices, ranking_coverage = self.dream_team_by_rankings(affinity_df, team_size=4)



print(f"\nüìä STRATEGY COMPARISON:")

print(f"üéØ Hybrid Strategy ({len(hybrid_indices)} members): {hybrid_coverage:.2f} coverage")

print(f"ü§ñ Pure Greedy ({len(greedy_indices)} members): {greedy_coverage:.2f} coverage")

print(f"üìà Top Rankings (4 members): {ranking_coverage:.2f} coverage")



# Show detailed comparison

strategies = [

("HYBRID (Top 2 + Coverage)", hybrid_indices, hybrid_coverage),

("PURE GREEDY", greedy_indices, greedy_coverage),

("TOP RANKINGS", ranking_indices, ranking_coverage)

]



for strategy_name, indices, coverage in strategies:

print(f"\n{strategy_name}:")

for i, idx in enumerate(indices):

name = affinity_df.index[idx]

avg_score = affinity_df.iloc[idx].mean()

role = "PI" if i == 0 else f"Co-I {i}"

print(f" {name} ({role}) - Avg Score: {avg_score:.2f}")



# Determine which strategy to use - prioritize hybrid if competitive

best_coverage = max(hybrid_coverage, greedy_coverage, ranking_coverage)



if hybrid_coverage >= best_coverage - 1.0: # Hybrid is within 1 point of best

print(f"\nüéØ RECOMMENDATION: Use Hybrid Strategy")

print(f" ‚úÖ Guarantees top performers (grant experience + keyword matching)")

print(f" ‚úÖ Optimizes coverage for remaining slots")

print(f" üìä Coverage: {hybrid_coverage:.2f} (competitive with best: {best_coverage:.2f})")

best_indices = hybrid_indices

best_strategy = "hybrid"

elif ranking_coverage > greedy_coverage:

print(f"\nüìà RECOMMENDATION: Use Rankings Team (+{ranking_coverage - greedy_coverage:.2f} better coverage)")

best_indices = ranking_indices

best_strategy = "rankings"

else:

print(f"\nü§ñ RECOMMENDATION: Use Greedy Team (+{greedy_coverage - ranking_coverage:.2f} better coverage)")

best_indices = greedy_indices

best_strategy = "greedy"



return best_indices, best_strategy, {

"hybrid": hybrid_coverage,

"greedy": greedy_coverage,

"rankings": ranking_coverage

}



def get_team_evidence(self, affinity_df, team_indices, skills_list):

"""Collect supporting evidence (papers) for each skill covered by the team."""

print("\nüìö Collecting Supporting Evidence...")

team_evidence = {} # skill -> list of paper IDs



for i, skill in enumerate(skills_list):

# Find the best researcher for this skill in the selected team

team_scores = affinity_df.iloc[team_indices, i]

if not team_scores.empty and team_scores.max() > 0:

best_member_name = team_scores.idxmax()

best_member_idx_in_affinity_df = affinity_df.index.get_loc(best_member_name)

best_member_id = None

# Find the OpenAlex ID for the best member

for match in self.researcher_metadata.itertuples():

if match.researcher_name == best_member_name:

best_member_id = match.researcher_openalex_id

break



if best_member_id and best_member_id in self.evidence_index:

# Get papers from evidence index for this researcher and skill

skill_in_index = None

# Find the closest matching skill name in the evidence index

for index_skill in self.evidence_index[best_member_id].keys():

if skill.lower() in index_skill.lower() or index_skill.lower() in skill.lower():

skill_in_index = index_skill

break



if skill_in_index and self.evidence_index[best_member_id][skill_in_index]:

# Select top 3 papers for this skill from the best member

# Prioritize by citations or recency if available, otherwise just take first few

papers = self.evidence_index[best_member_id][skill_in_index]

# For simplicity, just take the first 3 papers

team_evidence[skill] = list(set(papers))[:3]

else:

team_evidence[skill] = [] # No specific evidence found for this skill

else:

team_evidence[skill] = [] # Researcher not found in evidence index



else:

team_evidence[skill] = [] # No team member covers this skill well



print(f"‚úÖ Collected evidence for {len([k for k,v in team_evidence.items() if v])}/{len(skills_list)} skills")

return team_evidence





def create_dream_team_report(self, affinity_df, skills_list, solicitation_data, max_team_size=4):

"""Create comprehensive dream team report with strategic analysis."""

print("\nüöÄ CREATING DREAM TEAM STRATEGIC REPORT")

print("=" * 60)



# Run team selection algorithm (using the hybrid strategy as recommended)

team_indices, selection_history = self.dream_team_hybrid_strategy(affinity_df, guaranteed_top_n=2, max_team_size=max_team_size)



# Generate coverage analysis

coverage_report = self.generate_coverage_report(affinity_df, team_indices, skills_list)



# Collect evidence

team_evidence = self.get_team_evidence(affinity_df, team_indices, skills_list)





# Generate strategic analysis

strategic_analysis = self.generate_strategic_analysis(coverage_report, skills_list, solicitation_data)



return DreamTeamReport(

team_members=coverage_report['team_members'],

overall_coverage_score=coverage_report['overall_coverage_score'],

skill_analysis=coverage_report['skill_analysis'],

strategic_analysis=strategic_analysis,

selection_history=selection_history,

generated_at=datetime.now().isoformat()

), team_evidence



def format_markdown_report(self, dream_team_report, solicitation_title, team_evidence):

"""Format the strategic report as a human-readable Markdown file."""

report = f"# NSF Dream Team Strategic Report\n\n"

report += f"**Solicitation:** {solicitation_title}\n"

report += f"**Generated:** {dream_team_report.generated_at}\n"

report += f"**Overall Team Coverage Score:** **`{dream_team_report.overall_coverage_score:.2f} / 100`**\n\n"



# Team Summary Table

report += f"## üèÜ Recommended Dream Team\n\n"

report += "| Role | Researcher | Avg. Affinity | Top Expertise Areas |\n"

report += "|:---|:---|:---:|:---|\n"

for i, member in enumerate(dream_team_report.team_members):

role = "**Principal Investigator (PI)**" if i == 0 else f"Co-Investigator {i}"

top_skills = ", ".join([s['skill'] for s in member['top_skills']])

report += f"| {role} | {member['name']} | `{member['avg_affinity']:.2f}` | {top_skills} |\n"



# Coverage Analysis Table

report += f"\n## üìä Skills Coverage Analysis\n\n"

report += "| Skill / Expertise Area | Coverage | Level | Primary Expert | Supporting Evidence |\n" # Added Evidence column

report += "|:---|:---:|:---|:---|:---|\n" # Updated table format

for skill in sorted(dream_team_report.skill_analysis, key=lambda x: x['coverage_score'], reverse=True):

level_emoji = "üü¢" if skill['level'] == 'High' else "üü°" if skill['level'] == 'Medium' else "üî¥"

evidence_links = []

if skill['skill'] in team_evidence and team_evidence[skill['skill']]:

evidence_links = [f"[Paper {j+1}]({paper_id})" for j, paper_id in enumerate(team_evidence[skill['skill']])]



report += f"| {skill['skill']} | `{skill['coverage_score']:.2f}` | {level_emoji} {skill['level']} | {skill['expert']} | {', '.join(evidence_links) if evidence_links else 'None'} |\n" # Added evidence links





# Strategic Analysis

report += f"\n## üß† AI-Powered Strategic Analysis (via Groq)\n\n"

report += dream_team_report.strategic_analysis + "\n"



# Selection History

report += f"\n## üéØ Team Selection Process\n\n"

for entry in dream_team_report.selection_history:

report += f"**Step {entry['step']}:** {entry['action']} - {entry['researcher_name']}\n"

report += f"- Reason: {entry['reason']}\n"

report += f"- Team Coverage: {entry['team_coverage']:.2f}\n\n"



return report



def run_complete_analysis(self, solicitation_obj, top_n_researchers=20, max_team_size=4):

"""Run the complete analysis pipeline: matching ‚Üí affinity matrix ‚Üí dream team ‚Üí report."""

print("üöÄ STARTING COMPLETE UNIFIED ANALYSIS PIPELINE")

print("=" * 70)



# Phase 1: Researcher Matching

print("\nüìç PHASE 1: RESEARCHER MATCHING & RANKING")

matching_results = self.search_researchers(solicitation_obj)



# Display top matches

print("\nüèÜ TOP 10 RESEARCHER MATCHES:")

print(f"{'Rank':<4} {'Name':<30} {'Final':<8} {'Academic':<9} {'Sparse':<8} {'Dense':<8} {'Papers':<7}")

print("-" * 80)

for i, match in enumerate(matching_results.top_matches[:10], 1):

print(f"{i:<4} {match.researcher_name[:29]:<30} "

f"{match.final_affinity_score:<8.1f} {match.academic_expertise_score:<9.1f} "

f"{match.s_sparse:<8.1f} {match.s_dense:<8.1f} {match.total_papers:<7}")



# Phase 2: Affinity Matrix Creation

print(f"\nüìç PHASE 2: AFFINITY MATRIX CREATION")

affinity_df = self.create_affinity_matrix(matching_results, top_n_researchers)



# Phase 3: Dream Team Assembly

print(f"\nüìç PHASE 3: DREAM TEAM ASSEMBLY & STRATEGIC ANALYSIS")

skills_list = matching_results.skills_analyzed

solicitation_data = {'title': solicitation_obj.title}

dream_team_report, team_evidence = self.create_dream_team_report(affinity_df, skills_list, solicitation_data, max_team_size)





# Phase 4: Generate Reports

print(f"\nüìç PHASE 4: REPORT GENERATION")

markdown_report = self.format_markdown_report(dream_team_report, solicitation_obj.title, team_evidence)



# Save all results

timestamp = int(time.time())

base_filename = f"unified_analysis_{timestamp}"



# Save matching results

matching_file = f"{output_dir}/{base_filename}_matching_results.json"

with open(matching_file, 'w', encoding='utf-8') as f:

json.dump(asdict(matching_results), f, indent=2, ensure_ascii=False, default=str)

print(f"üíæ Saved matching results: {matching_file}")



# Save affinity matrix

affinity_file = f"{output_dir}/{base_filename}_affinity_matrix.csv"

affinity_df.to_csv(affinity_file)

print(f"üíæ Saved affinity matrix: {affinity_file}")



# Save dream team report

report_file = f"{output_dir}/{base_filename}_dream_team_report.json"

with open(report_file, 'w', encoding='utf-8') as f:

json.dump(asdict(dream_team_report), f, indent=2, ensure_ascii=False, default=str)

print(f"üíæ Saved dream team report: {report_file}")



# Save markdown report

markdown_file = f"{output_dir}/{base_filename}_strategic_report.md"

with open(markdown_file, 'w', encoding='utf-8') as f:

f.write(markdown_report)

print(f"üíæ Saved markdown report: {markdown_file}")



# Save evidence data

evidence_file = f"{output_dir}/{base_filename}_team_evidence.json"

with open(evidence_file, 'w', encoding='utf-8') as f:

json.dump(team_evidence, f, indent=2, ensure_ascii=False, default=str)

print(f"üíæ Saved team evidence: {evidence_file}")



# Display final summary

self.display_final_summary(matching_results, dream_team_report, team_evidence)



return {

'matching_results': matching_results,

'affinity_matrix': affinity_df,

'dream_team_report': dream_team_report,

'team_evidence': team_evidence,

'markdown_report': markdown_report,

'files_saved': {

'matching': matching_file,

'affinity': affinity_file,

'report': report_file,

'markdown': markdown_file,

'evidence': evidence_file

}

}



def display_final_summary(self, matching_results, dream_team_report, team_evidence):

"""Display a comprehensive summary of the analysis."""

print("\n" + "="*70)

print("üìã UNIFIED ANALYSIS SUMMARY")

print("="*70)



print(f"üîç RESEARCHER MATCHING:")

print(f" ‚Ä¢ Analyzed {matching_results.total_researchers} total researchers")

print(f" ‚Ä¢ {matching_results.eligible_researchers} eligible researchers")

print(f" ‚Ä¢ Processing time: {matching_results.processing_time_seconds}s")



print(f"\nüéØ DREAM TEAM ASSEMBLY:")

print(f" ‚Ä¢ Selected {len(dream_team_report.team_members)} optimal team members")

print(f" ‚Ä¢ Strategy: Hybrid (Top 2 performers + coverage optimization)")

print(f" ‚Ä¢ Overall coverage score: {dream_team_report.overall_coverage_score:.2f}/100")



print(f"\nüë• RECOMMENDED TEAM:")

for i, member in enumerate(dream_team_report.team_members):

role = "PI" if i == 0 else f"Co-I {i}"

print(f" ‚Ä¢ {member['name']} ({role}) - Affinity: {member['avg_affinity']:.2f}")



# Check for gaps

low_skills = [s for s in dream_team_report.skill_analysis if s['level'] == 'Low']

medium_skills = [s for s in dream_team_report.skill_analysis if s['level'] == 'Medium']

high_skills = [s for s in dream_team_report.skill_analysis if s['level'] == 'High']



print(f"\nüìä SKILL COVERAGE BREAKDOWN:")

print(f" üü¢ High Coverage: {len(high_skills)} skills")

print(f" üü° Medium Coverage: {len(medium_skills)} skills")

print(f" üî¥ Low Coverage: {len(low_skills)} skills")



if low_skills:

print(f"\nüî¥ TOP GAPS TO ADDRESS:")

for skill in sorted(low_skills, key=lambda x: x['coverage_score'])[:3]:

print(f" ‚Ä¢ {skill['skill']} (Coverage: {skill['coverage_score']:.1f})")

if len(low_skills) > 3:

print(f" ‚Ä¢ ... and {len(low_skills) - 3} more (see full report)")

else:

print(f"\nüü¢ EXCELLENT COVERAGE: No significant skill gaps identified")



print(f"\n‚úÖ ANALYSIS COMPLETE! Check saved files for detailed reports.")

print(f"üìö EVIDENCE: {sum(len(evidence) for evidence in team_evidence.values())} supporting papers collected")

print(f"üí° TIP: Review the markdown report for AI-powered strategic recommendations and evidence.")# ==============================================================================# MAIN EXECUTION# ==============================================================================def run_unified_analysis():

"""Main function to run the complete unified analysis."""



# Load solicitation

print("üìã Loading solicitation...")

with open(solicitation_file, 'r', encoding='utf-8') as f:

solicitation_data = json.load(f)



# Convert to object

class SolicitationObj:

def __init__(self, data):

for key, value in data.items():

setattr(self, key, value)



solicitation_obj = SolicitationObj(solicitation_data)

print(f"‚úÖ Loaded: {solicitation_obj.title}")



# Initialize unified system

system = UnifiedResearcherSystem(researcher_data_dir)



# Run complete analysis

results = system.run_complete_analysis(

solicitation_obj,

top_n_researchers=20, # Adjust as needed

max_team_size=4 # Adjust as needed

)



return results# RUN THE UNIFIED SYSTEMif __name__ == "__main__":

results = run_unified_analysis()