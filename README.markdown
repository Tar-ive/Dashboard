# NSF Researcher Matching API

A comprehensive FastAPI-based system for matching researchers to NSF solicitations and assembling optimal research teams using advanced machine learning algorithms.

## ğŸš€ Features

- **PDF Upload & Analysis**: Upload and analyze NSF solicitation PDFs with intelligent text extraction
- **Researcher Matching**: Advanced hybrid search algorithm for matching researchers to solicitations
- **Dream Team Assembly**: Optimize research team composition using affinity matrices and selection strategies
- **Real-time Processing**: Asynchronous processing with status tracking
- **RESTful API**: Complete REST API with comprehensive documentation
- **Docker Support**: Containerized deployment with Docker Compose
- **Interactive Notebooks**: Jupyter notebooks for data analysis and exploration

## ğŸ“ Project Structure

```
Dashboard/
â”œâ”€â”€ README.md                    # Project documentation
â”œâ”€â”€ LICENSE                     # Project license
â”œâ”€â”€ notebooks/                  # Jupyter notebooks for analysis
â”‚   â”œâ”€â”€ brahman.ipynb          # Research analysis notebook
â”‚   â”œâ”€â”€ dashboard_CADS.ipynb   # Dashboard prototype
â”‚   â””â”€â”€ krishna.ipynb          # Data exploration notebook
â””â”€â”€ backend/                   # FastAPI backend service
    â”œâ”€â”€ .env.example           # Environment variables template
    â”œâ”€â”€ .gitignore             # Git ignore rules
    â”œâ”€â”€ app/                   # Main application code
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ main.py           # FastAPI application entry point
    â”‚   â”œâ”€â”€ api/              # API route handlers
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ solicitations.py  # Solicitation endpoints
    â”‚   â”‚   â”œâ”€â”€ matching.py      # Matching endpoints
    â”‚   â”‚   â””â”€â”€ teams.py        # Dream team endpoints
    â”‚   â”œâ”€â”€ config.py          # Configuration management
    â”‚   â”œâ”€â”€ core/              # Core functionality
    â”‚   â”œâ”€â”€ dependencies.py    # Dependency injection
    â”‚ |   â”œâ”€â”€ models/          # Data models
    â”‚   â”œâ”€â”€ processors/        # Data processing modules
    â”‚   â”œâ”€â”€ services/          # Business logic services
    â”‚   â”œâ”€â”€ storage/           # Data storage handling
    â”‚   â””â”€â”€ utils/             # Utility functions
    â”œâ”€â”€ data/                  # Data storage
    â”‚   â”œâ”€â”€ uploads/           # Uploaded PDF files
    â”‚   â””â”€â”€ outputs/           # Generated outputs
    â”œâ”€â”€ docker-compose.yml     # Docker composition
    â”œâ”€â”€ Dockerfile             # Docker build instructions
    â”œâ”€â”€ requirements.txt       # Python dependencies
    â”œâ”€â”€ scripts/               # Utility scripts
    â””â”€â”€ tests/                 # Test files
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- Python 3.8+
- pip
- Docker & Docker Compose (optional)

### Local Development Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/Tar-ive/Dashboard.git
   cd Dashboard
   ```

2. **Set up the backend**
   ```bash
   cd backend
   pip install -r requirements.txt
   ```

3. **Configure environment variables**
   ```bash
   cp .env.example .env
   # Edit .env file with your configuration
   ```

4. **Run the application**
   ```bash
   uvicorn app.main:app --reload
   ```

5. **Access the API**
   - API: http://localhost:8000
   - Documentation: http://localhost:8000/docs
   - Alternative docs: http://localhost:8000/redoc

### Docker Deployment

1. **Build and run with Docker Compose**
   ```bash
   cd backend
   docker-compose up -d
   ```

2. **Access the containerized API**
   - API: http://localhost:8000
   - Health check: http://localhost:8000/health

## ğŸ“š API Documentation

### Core Endpoints

#### Health Check
- `GET /` - Basic health check
- `GET /health` - Detailed health status

#### Solicitations API
- `GET /api/v1/solicitations/` - List all solicitations
- `POST /api/v1/solicitations/upload` - Upload PDF solicitation
- `POST /api/v1/solicitations/{solicitation_id}/analyze` - Analyze solicitation
- `GET /api/v1/solicitations/{solicitation_id}` - Get solicitation details

#### Matching API
- `GET /api/v1/matching/` - Get matching service info
- `POST /api/v1/matching/run` - Run matching algorithm
- `GET /api/v1/matching/{session_id}/status` - Get matching status
- `GET /api/v1/matching/{session_id}/results` - Get matching results
- `DELETE /api/v1/matching/{session_id}` - Delete matching session

#### Dream Teams API
- `GET /api/v1/teams/` - Get teams service info
- `POST /api/v1/teams/assemble` - Assemble dream team
- `GET /api/v1/teams/{team_id}` - Get team details
- `DELETE /api/v1/teams/{team_id}` - Delete team session
- `GET /api/v1/teams/{team_id}/matrix` - Export affinity matrix
- `POST /api/v1/teams/{team_id}/optimize` - Optimize team composition
- `POST /api/v1/teams/{team_id}/compare` - Compare selection strategies

### Request/Response Examples

#### Upload Solicitation
```bash
curl -X POST "http://localhost:8000/api/v1/solicitations/upload" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@solicitation.pdf"
```

#### Run Matching
```bash
curl -X POST "http://localhost:8000/api/v1/matching/run" \
  -H "Content-Type: application/json" \
  -d '{
    "solicitation_id": "123",
    "algorithm": "hybrid",
    "max_results": 10
  }'
```

#### Assemble Dream Team
```bash
curl -X POST "http://localhost:8000/api/v1/teams/assemble" \
  -H "Content-Type: application/json" \
  -d '{
    "solicitation_id": "123",
    "team_size": 5,
    "strategy": "optimal"
  }'
```

## ğŸ§ª Data Models

### Core Models
- **SolicitationResponse**: Uploaded solicitation metadata
- **SolicitationAnalysis**: Analyzed solicitation data
- **MatchingRequest**: Matching algorithm parameters
- **MatchingResults**: Researcher matching results
- **DreamTeamRequest**: Team assembly parameters
- **DreamTeamReport**: Assembled team details
- **ResearcherMatch**: Individual researcher match data
- **AffinityMatrixExport**: Team affinity matrix data

## ğŸ”§ Services Architecture

### Core Services
1. **PDFService**: Handles PDF upload and text extraction
2. **MatchingService**: Implements hybrid search algorithms
3. **DreamTeamService**: Optimizes team composition
4. **AnalysisService**: Performs solicitation analysis
5. **StorageService**: Manages data persistence

### Processing Pipeline
1. **PDF Upload** â†’ Text Extraction â†’ Content Analysis
2. **Solicitation Analysis** â†’ Keyword Extraction â†’ Skill Mapping
3. **Researcher Matching** â†’ Similarity Scoring â†’ Ranking
4. **Team Assembly** â†’ Affinity Calculation â†’ Optimization

## ğŸ“Š Notebooks

### Available Notebooks
1. **brahman.ipynb**: Research analysis and algorithm development
2. **dashboard_CADS.ipynb**: Dashboard prototype and visualization
3. **krishna.ipynb**: Data exploration and preprocessing

### Running Notebooks
```bash
cd notebooks
jupyter notebook
```

## ğŸ§ª Testing

### Run Tests
```bash
cd backend
python -m pytest tests/
```

### Test Coverage
```bash
python -m pytest --cov=app tests/
```

## ğŸ“ˆ Performance & Scalability

### Optimization Features
- **Asynchronous Processing**: Non-blocking API operations
- **Caching**: Intelligent result caching
- **Batch Processing**: Efficient bulk operations
- **Resource Management**: Optimized memory usage

### Monitoring
- Health check endpoints for monitoring
- Detailed status tracking for long-running operations
- Performance metrics collection

## ğŸš€ Deployment

### Production Deployment

1. **Environment Setup**
   ```bash
   export ENVIRONMENT=production
   export DATABASE_URL=your_production_db
   export SECRET_KEY=your_secret_key
   ```

2. **Docker Production Build**
   ```bash
   docker build -t nsf-matcher:latest .
   docker run -p 8000:8000 nsf-matcher:latest
   ```

3. **Kubernetes Deployment** (Optional)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nsf-matcher
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nsf-matcher
  template:
    metadata:
      labels:
        app: nsf-matcher
    spec:
      containers:
      - name: nsf-matcher
        image: nsf-matcher:latest
        ports:
        - containerPort: 8000
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines
- Follow PEP 8 style guidelines
- Write comprehensive tests
- Update documentation
- Use semantic commit messages

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For support, please:
1. Check the API documentation
2. Review existing issues
3. Create a new issue with detailed description

## ğŸ™ Acknowledgments

- NSF for solicitation data standards
- FastAPI team for the excellent framework
- Contributors and researchers who made this possible

## ğŸ“Š API Status

- **Version**: 1.0.0
- **Status**: Active Development
- **Last Updated**: July 2025
- **Endpoints**: 17 active endpoints
- **Features**: PDF Processing, Matching, Team Assembly

**Built with â¤ï¸ for the research community**